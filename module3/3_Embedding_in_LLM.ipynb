{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Coursebook: Understanding Embedding in LLM**\n",
    "\n",
    "- Part 3 of Understanding Embedding in LLM\n",
    "- Course Length: 9 hours\n",
    "- Last Updated: July 2023\n",
    "---\n",
    "\n",
    "Developed by Algoritma's Research and Development division"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "The coursebook is part of the **Large Language Models Specialization** developed by [Algoritma](https://algorit.ma/). The coursebook is intended for a restricted audience only, i.e. the individuals and organizations having received this coursebook directly from the training organization. It may not be reproduced, distributed, translated or adapted in any form outside these individuals and organizations without permission.Algoritma is a data science education center based in Jakarta. We organize workshops and training programs to help working professionals and students gain mastery in various data science sub-fields: data visualization, machine learning, data modeling, statistical inference etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Embedding in LLM "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Objectives\n",
    "\n",
    "- **Understanding Embeddings in Large Language Models (LLM) for Natural Language Processing**\n",
    "   - Basic concepts of embeddings in LLM\n",
    "   - Usage of embeddings in natural language processing\n",
    "   - Demonstration of embeddings usage in text analysis\n",
    "\n",
    "\n",
    "- **Advanced Embeddings in Large Language Models (LLM) for Text Processing**\n",
    "   - In-depth understanding of embeddings in LLM\n",
    "   - Implementation of embeddings in text processing using Python\n",
    "   - Demonstration of embedding techniques in text processing tasks\n",
    "\n",
    "\n",
    "- **Advanced Applications of Embeddings in Text Processing with Large Language Models (LLM)**\n",
    "   - Application of embeddings in advanced text processing\n",
    "   - Usage of embeddings for text classification and contextual understanding\n",
    "   - Demonstration of embeddings usage in advanced tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Embeddings in Large Language Models (LLM) for Natural Language Processing\n",
    "\n",
    "We have created a GPT question and answering system using Large Language Models (LLMs) that can generate answers based on our data. Now, let's delve deeper into how LLMs understand natural language by exploring the concept of embeddings.\n",
    "\n",
    "In natural language processing (NLP), **embeddings** are representations of **words or text as numerical vectors**. These vectors capture the **semantic and contextual** information of the text, allowing the model to understand the meaning and relationships between words. In simpler terms, embeddings help the chatbot understand the meaning of words and how they relate to each other.\n",
    "\n",
    "Imagine you have a chatbot designed to assist customers with their inquiries. When a customer asks a question, the chatbot needs to understand the meaning of the question and provide a relevant answer. This is where embeddings come into play. The chatbot is trained on a large amount of text data and learns to associate words with their respective embeddings. These embeddings encode the information about the words' meaning and context.\n",
    "\n",
    "For example, if a customer asks, \"What are the payment options available?\" the chatbot uses the embeddings to understand the meaning of the words \"payment\" and \"options\" and their relationship within the sentence. It can then provide an appropriate response by retrieving information from its knowledge base.\n",
    "\n",
    "Embeddings enable the chatbot to **make sense** of the customer's input and generate accurate and contextually relevant responses. By capturing the meaning and relationships between words, embeddings enhance the chatbot's understanding of natural language and improve its ability to generate meaningful and coherent answers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Concept of Embedding (Vector)\n",
    "\n",
    "A vector (or embedding) is an **array of numbers**. That on its own is exciting, but what is even more exciting is that these arrays can represent more complex data like text, images, audio or even video. In the case of text, these representations are designed to capture **semantic and syntactic** relationships between words, allowing algorithms to understand and process language more effectively.\n",
    "\n",
    "Word embeddings, specifically, are dense vector representations that encode the meaning of a word based on its context in a large corpus of text. In simpler terms, they map words to numerical vectors in a high-dimensional space, where similar words are located closer to each other. This is done in a vector database (we will talk about this later)\n",
    "\n",
    "Creating these embeddings is done by an embedding model. There are multiple embedding models that can be used. OpenAI also provide embedding model but we will use free LLM model so we don't ran out of credit. We will use **`\"all-MiniLM-L6-v2\"`** embedding model.\n",
    "\n",
    "Making embeddings can be visualised in the following way:\n",
    "\n",
    "![embedding](assets/embedding.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This embedding process apply in many LLM implementation, for example QnA system or GPT chatbot. The question asked to the chatbot will be embedded as well, and on the basis of similarity search, the retriever will return the embeddings with the data to answer the question. After this, the LLM will return a coherent and well-structured answer.\n",
    "\n",
    "But let's dive deep the concept one by one start by how to perform embedding from raw text to vector form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/llm_dev/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "\n",
    "# create the open-source embedding function\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This embedding function is based on an open-source sentence transformer model, which converts sentences or text into numerical embeddings that capture the semantic meaning and contextual information of the text. Let's create an example sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"This is document about cat\",\n",
    "    \"This is document about car\",\n",
    "    \"Example of the long sentences: China increased its coal-fired power capacity by 42.9 GW, or 4.5%, in the 18 months to June 2019, according to a report by Global Energy Monitor. The study also found that another 121.3 GW of coal-fired power plants are under construction in China, which has pledged to reduce its coal usage. However, the country’s absolute coal consumption has still increased in line with rising energy demand. China accounts for more than 40% of the world's total coal generation capacity.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.035840701311826706,\n",
       " 0.0844104215502739,\n",
       " 0.0044357795268297195,\n",
       " 0.061324890702962875,\n",
       " -0.09679649770259857,\n",
       " -0.011024951934814453,\n",
       " -0.03996600955724716,\n",
       " 0.02713777683675289,\n",
       " -0.036853302270174026,\n",
       " 0.04033125564455986]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform embedding using embed_documents()\n",
    "embedded_sentences = embedding_function.embed_documents(sentences)\n",
    "\n",
    "# show embedded result\n",
    "embedded_sentences[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of this code is the result of performing embedding using the `embed_documents()` method of the `embedding_function`. The `sentences` variable represents a list of sentences or text that we want to embed. The `embed_documents()` method takes these sentences as input and generates their corresponding embeddings. \n",
    "\n",
    "The variable `embedded_sentences` stores the embedded representations of the input sentences. It is a numerical representation of the sentences that captures their semantic meaning and context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See len of embedded sentences\n",
    "len(embedded_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have three sentences and have embedded all of them. Let's see the embedding shape all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n",
      "384\n",
      "384\n"
     ]
    }
   ],
   "source": [
    "# Shape of embedded sentences\n",
    "for text in embedded_sentences:\n",
    "    print(len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each embedded sentence is represented as a numerical vector or array of length 384. This length is determined by the embedding model used, and it indicates the **dimensionality or the number of features in the embedding space.** Each element of the vector captures specific information about the corresponding sentence's semantic meaning and context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.035840701311826706,\n",
       " 0.0844104215502739,\n",
       " 0.0044357795268297195,\n",
       " 0.061324890702962875,\n",
       " -0.09679649770259857,\n",
       " -0.011024951934814453,\n",
       " -0.03996600955724716,\n",
       " 0.02713777683675289,\n",
       " -0.036853302270174026,\n",
       " 0.04033125564455986]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the first 10 vector of first sentences\n",
    "embedded_sentences[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The statement indicates that the embedding model, specifically the [sentence-transformers/msmarco-MiniLM-L-12-v3](sentence-transformers/msmarco-MiniLM-L-12-v3) model, generates a fixed-size vector of 384 dimensions for any given sentence, regardless of its length. This model is designed to map sentences and paragraphs to a dense vector space with 384 dimensions.\n",
    "\n",
    "The purpose of this embedding is to capture the semantic meaning of sentences and enable tasks such as semantic search, where similarity between sentences can be measured in this vector space. By representing sentences in a fixed-size vector format, the model facilitates efficient comparison and retrieval of semantically similar sentences.\n",
    "\n",
    "In summary, regardless of the length of the input sentence, the embedding model consistently produces a 384-dimensional vector representation that captures the semantic information of the sentence. This representation can be used for various NLP tasks, including semantic search, where similarity between sentences is important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Similarity Between Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have embedding three sentences (documents) above. \n",
    "\n",
    "> - What if we want to know which document contains relevance information about our question?\n",
    "> > We can resolve this problem by embedding our question to vector dimension and **compute the similarity** between our question and our documents.\n",
    "\n",
    "The similarity compute using `cosine distance` which the lower the distances, the similar the vector is.\n",
    "\n",
    "For example if we want to know which document contains information about China and coal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed the question/query\n",
    "embed_query = embedding_function.embed_documents(['China and coal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.97059791, 0.92054651, 0.43505044]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the cosine_distance\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "\n",
    "# Compute the cosine distance between query and documents\n",
    "cosine_distances(embed_query, embedded_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results above, we can see that the third document has the lowest distance, indicating that it is the most relevant to the query \"China and coal\". This is not surprising, as the third document is a summary news article specifically about China's coal-powered plants. The lower distance suggests a higher similarity between the document and the query, indicating that it contains information closely related to the topic of interest.\n",
    "\n",
    "Let's see another example. What if we want to know which document contains about vehicle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.69098626, 0.20956949, 0.99632422]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = [\"show document about vehicle\"]\n",
    "embed_query = embedding_function.embed_documents(query)\n",
    "\n",
    "cosine_distances(embed_query, embedded_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the second document contains the lowest distance, lets see the second document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is document about cat',\n",
       " 'This is document about car',\n",
       " \"Example of the long sentences: China increased its coal-fired power capacity by 42.9 GW, or 4.5%, in the 18 months to June 2019, according to a report by Global Energy Monitor. The study also found that another 121.3 GW of coal-fired power plants are under construction in China, which has pledged to reduce its coal usage. However, the country’s absolute coal consumption has still increased in line with rising energy demand. China accounts for more than 40% of the world's total coal generation capacity.\"]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show second document\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the second document doesn't contains any \"vehicle\" word but contains \"car\" which semantically we know that car is vehicle. \n",
    "\n",
    "Also notice that the first and second document just have 1 different letter \"cat\" and \"car\". But the distance pretty far. \n",
    "\n",
    "This is because the embedding model embed the sentence based on its semantic textual meaning instead of just the letter/word like conventional embedding function.\n",
    "\n",
    "Let's use another example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.39287085, 0.61589002, 1.00654091]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = [\"show document about animals\"]\n",
    "embed_query = embedding_function.embed_documents(query)\n",
    "\n",
    "cosine_distances(embed_query, embedded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is document about cat'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though the documents do not explicitly contain the word \"animals,\" by computing the cosine distance of the embedding vectors, we can identify the document that represents the semantic meaning of our query. The cosine distance captures the similarity between the vectors, allowing us to find documents that capture the context and concept related to \"animals,\" even if the exact word is not present. This demonstrates the power of embedding models in capturing the semantic meaning and enabling effective information retrieval and search tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Embedding in Large Language Models (LLM) for Text Processing\n",
    "\n",
    "The ability of embedding to handle text data is crucial for addressing the demands of today's industries. Embedding allows us to process and understand textual information effectively, enabling a wide range of text processing tasks.\n",
    "\n",
    "One significant application of embedding is in large language models (LLMs), which leverage advanced embedding techniques to comprehend and generate natural language. By utilizing embedding in LLMs, we can tackle various industrial challenges more efficiently.\n",
    "\n",
    "In this section, we will explore the use of **Chroma DB**, a powerful embedding-based database, to enhance text processing capabilities. By training the model on relevant data, we can leverage the embedded representations of text to perform tasks like question-answering. This approach enables us to extract meaningful information from the data and provide accurate responses to user queries.\n",
    "\n",
    "By harnessing the power of embedding in LLMs and leveraging technologies like Chroma DB, we can significantly improve the **efficiency and effectiveness** of text processing in industries. This opens up new opportunities for automating tasks, gaining insights from textual data, and enhancing decision-making processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Database (CHROMA DB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with Large Language Models (LLMs) like GPT-4 or Google's PaLM 2, we will often be working with big amounts of unstructured, textual data. Structured data can just be stored in a SQL database, but that is much harder with unstructured data. When we for instance have a lot of text files like above example with information on a certain topic, it might be good to store this information in a different way in order to retrieve the desired data in the most efficient way. The answer to this: **Vector Databases**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The specific vector database that we will use is the **ChromaDB** vector database.\n",
    "\n",
    "[Chroma Website](https://docs.trychroma.com/getting-started#:~:text=Chroma%20is%20a%20database%20for,hosted%20version%20is%20coming%20soon!):\n",
    "\n",
    "> Chroma is a database for building AI applications with embeddings. It comes with everything you need to get started built in, and runs on your machine. ChromaDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using `Chroma`, we can streamline the process of embedding and computing cosine distances, as it provides built-in functionality for these tasks.\n",
    "\n",
    "Both `Chroma` and `LangChain` are integrated, allowing for seamless usage. To take advantage of this integration, we need to import the necessary functions from the respective libraries. This integration simplifies the implementation of text processing tasks by providing convenient methods for embedding text, computing cosine distances, and utilizing these functionalities within the broader context of `LangChain`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To utilize `Chroma DB` and `LangChain`, we need to import the necessary libraries and modules. \n",
    "\n",
    "- `SentenceTransformerEmbeddings` from `langchain.embeddings.sentence_transformer`: to generate embeddings for sentences using a pre-trained Sentence Transformer model.\n",
    "- `CharacterTextSplitter` from `langchain.text_splitter`: split text documents into smaller chunks or segments, which can be useful for efficient processing and analysis.\n",
    "- `Chroma` from `langchain.vectorstores`: Chroma is a vector store that enables us to store and query embedded text data efficiently.\n",
    "- `TextLoader` from `langchain.document_loaders`: provides functionality to load text documents from various sources, such as files or directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the document and split it into chunks\n",
    "loader = TextLoader(\"data_input/state_of_the_union.txt\")\n",
    "document = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Madam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and the Cabinet. Justices of the Supreme Court. My fellow Americans.  \\n\\nLast year COVID-19 kept us apart. This year we are finally together again. \\n\\nTonight, we meet as Democrats Republicans and Independents. But most importantly as Americans. \\n\\nWith a duty to one another to the American people to the Constitution. \\n\\nAnd with an unwavering resolve that freedom will always triumph over tyranny. \\n\\nSix days ago, Russia’s Vladimir Putin sought to shake the foundations of the free world thinking he could make it bend to his menacing ways. But he badly miscalculated. \\n\\nHe thought he could roll into Ukraine and the world would roll over. Instead he met a wall of strength he never imagined. \\n\\nHe met the Ukrainian people. \\n\\nFrom President Zelenskyy to every Ukrainian, their fearlessness, their courage, their determination, inspires the world. \\n\\nGroups of citizens blocking tanks with their bodies. Everyone from students to retirees teachers turned soldiers defending their homeland. \\n\\nIn this struggle as President Zelenskyy said in his speech to the European Parliament “Light will win over darkness.” The Ukrainian Ambassador to the United States is here tonight. \\n\\nLet each of us here tonight in this Chamber send an unmistakable signal to Ukraine and to the world. \\n\\nPlease rise if you are able and show that, Yes, we the United States of America stand with the Ukrainian people. \\n\\nThroughout our history we’ve learned this lesson when dictators do not pay a price for their aggression they cause more chaos.   \\n\\nThey keep moving.   \\n\\nAnd the costs and the threats to America and the world keep rising.   \\n\\nThat’s why the NATO Alliance was created to secure peace and stability in Europe after World War 2. \\n\\nThe United States is a member along with 29 other nations. \\n\\nIt matters. American diplomacy matters. American resolve matters. \\n\\nPutin’s latest attack on Ukraine was premeditated and unprovoked. \\n\\nHe rejected repeated efforts at diplomacy. \\n\\nHe thought the West and NATO wouldn’t respond. And he thought he could divide us at home. Putin was wrong. We were ready.  Here is what we did.   \\n\\nWe prepared extensively and carefully. \\n\\nWe spent months building a coalition of other freedom-loving nations from Europe and the Americas to Asia and Africa to confront Putin. \\n\\nI spent countless hours unifying our European allies. We shared with the world in advance what we knew Putin was planning and precisely how he would try to falsely justify his aggression.  \\n\\nWe countered Russia’s lies with truth.   \\n\\nAnd now that he has acted the free world is holding him accountable. \\n\\nAlong with twenty-seven members of the European Union including France, Germany, Italy, as well as countries like the United Kingdom, Canada, Japan, Korea, Australia, New Zealand, and many others, even Switzerland. \\n\\nWe are inflicting pain on Russia and supporting the people of Ukraine. Putin is now isolated from the world more than ever. \\n\\nTogether with our allies –we are right now enforcing powerful economic sanctions. \\n\\nWe are cutting off Russia’s largest banks from the international financial system.  \\n\\nPreventing Russia’s central bank from defending the Russian Ruble making Putin’s $630 Billion “war fund” worthless.   \\n\\nWe are choking off Russia’s access to technology that will sap its economic strength and weaken its military for years to come.  \\n\\nTonight I say to the Russian oligarchs and corrupt leaders who have bilked billions of dollars off this violent regime no more. \\n\\nThe U.S. Department of Justice is assembling a dedicated task force to go after the crimes of Russian oligarchs.  \\n\\nWe are joining with our European allies to find and seize your yachts your luxury apartments your private jets. We are coming for your ill-begotten gains. \\n\\nAnd tonight I am announcing that we will join our allies in closing off American air space to all Russian flights – further isolating Russia – and adding an additional squeeze –on their economy. The Ruble has lost 30% of its value. \\n\\nThe Russian stock market has lost 40% of its value and trading remains suspended. Russia’s economy is reeling and Putin alone is to blame. \\n\\nTogether with our allies we are providing support to the Ukrainians in their fight for freedom. Military assistance. Economic assistance. Humanitarian assistance. \\n\\nWe are giving more than $1 Billion in direct assistance to Ukraine. \\n\\nAnd we will continue to aid the Ukrainian people as they defend their country and to help ease their suffering.  \\n\\nLet me be clear, our forces are not engaged and will not engage in conflict with Russian forces in Ukraine.  \\n\\nOur forces are not going to Europe to fight in Ukraine, but to defend our NATO Allies – in the event that Putin decides to keep moving west.  \\n\\nFor that purpose we’ve mobilized American ground forces, air squadrons, and ship deployments to protect NATO countries including Poland, Romania, Latvia, Lithuania, and Estonia. \\n\\nAs I have made crystal clear the United States and our Allies will defend every inch of territory of NATO countries with the full force of our collective power.  \\n\\nAnd we remain clear-eyed. The Ukrainians are fighting back with pure courage. But the next few days weeks, months, will be hard on them.  \\n\\nPutin has unleashed violence and chaos.  But while he may make gains on the battlefield – he will pay a continuing high price over the long run. \\n\\nAnd a proud Ukrainian people, who have known 30 years  of independence, have repeatedly shown that they will not tolerate anyone who tries to take their country backwards.  \\n\\nTo all Americans, I will be honest with you, as I’ve always promised. A Russian dictator, invading a foreign country, has costs around the world. \\n\\nAnd I’m taking robust action to make sure the pain of our sanctions  is targeted at Russia’s economy. And I will use every tool at our disposal to protect American businesses and consumers. \\n\\nTonight, I can announce that the United States has worked with 30 other countries to release 60 Million barrels of oil from reserves around the world.  \\n\\nAmerica will lead that effort, releasing 30 Million barrels from our own Strategic Petroleum Reserve. And we stand ready to do more if necessary, unified with our allies.  \\n\\nThese steps will help blunt gas prices here at home. And I know the news about what’s happening can seem alarming. \\n\\nBut I want you to know that we are going to be okay. \\n\\nWhen the history of this era is written Putin’s war on Ukraine will have left Russia weaker and the rest of the world stronger. \\n\\nWhile it shouldn’t have taken something so terrible for people around the world to see what’s at stake now everyone sees it clearly. \\n\\nWe see the unity among leaders of nations and a more unified Europe a more unified West. And we see unity among the people who are gathering in cities in large crowds around the world even in Russia to demonstrate their support for Ukraine.  \\n\\nIn the battle between democracy and autocracy, democracies are rising to the moment, and the world is clearly choosing the side of peace and security. \\n\\nThis is a real test. It’s going to take time. So let us continue to draw inspiration from the iron will of the Ukrainian people. \\n\\nTo our fellow Ukrainian Americans who forge a deep bond that connects our two nations we stand with you. \\n\\nPutin may circle Kyiv with tanks, but he will never gain the hearts and souls of the Ukrainian people. \\n\\nHe will never extinguish their love of freedom. He will never weaken the resolve of the free world. \\n\\nWe meet tonight in an America that has lived through two of the hardest years this nation has ever faced. \\n\\nThe pandemic has been punishing. \\n\\nAnd so many families are living paycheck to paycheck, struggling to keep up with the rising cost of food, gas, housing, and so much more. \\n\\nI understand. \\n\\nI remember when my Dad had to leave our home in Scranton, Pennsylvania to find work. I grew up in a family where if the price of food went up, you felt it. \\n\\nThat’s why one of the first things I did as President was fight to pass the American Rescue Plan.  \\n\\nBecause people were hurting. We needed to act, and we did. \\n\\nFew pieces of legislation have done more in a critical moment in our history to lift us out of crisis. \\n\\nIt fueled our efforts to vaccinate the nation and combat COVID-19. It delivered immediate economic relief for tens of millions of Americans.  \\n\\nHelped put food on their table, keep a roof over their heads, and cut the cost of health insurance. \\n\\nAnd as my Dad used to say, it gave people a little breathing room. \\n\\nAnd unlike the $2 Trillion tax cut passed in the previous administration that benefitted the top 1% of Americans, the American Rescue Plan helped working people—and left no one behind. \\n\\nAnd it worked. It created jobs. Lots of jobs. \\n\\nIn fact—our economy created over 6.5 Million new jobs just last year, more jobs created in one year  \\nthan ever before in the history of America. \\n\\nOur economy grew at a rate of 5.7% last year, the strongest growth in nearly 40 years, the first step in bringing fundamental change to an economy that hasn’t worked for the working people of this nation for too long.  \\n\\nFor the past 40 years we were told that if we gave tax breaks to those at the very top, the benefits would trickle down to everyone else. \\n\\nBut that trickle-down theory led to weaker economic growth, lower wages, bigger deficits, and the widest gap between those at the top and everyone else in nearly a century. \\n\\nVice President Harris and I ran for office with a new economic vision for America. \\n\\nInvest in America. Educate Americans. Grow the workforce. Build the economy from the bottom up  \\nand the middle out, not from the top down.  \\n\\nBecause we know that when the middle class grows, the poor have a ladder up and the wealthy do very well. \\n\\nAmerica used to have the best roads, bridges, and airports on Earth. \\n\\nNow our infrastructure is ranked 13th in the world. \\n\\nWe won’t be able to compete for the jobs of the 21st Century if we don’t fix that. \\n\\nThat’s why it was so important to pass the Bipartisan Infrastructure Law—the most sweeping investment to rebuild America in history. \\n\\nThis was a bipartisan effort, and I want to thank the members of both parties who worked to make it happen. \\n\\nWe’re done talking about infrastructure weeks. \\n\\nWe’re going to have an infrastructure decade. \\n\\nIt is going to transform America and put us on a path to win the economic competition of the 21st Century that we face with the rest of the world—particularly with China.  \\n\\nAs I’ve told Xi Jinping, it is never a good bet to bet against the American people. \\n\\nWe’ll create good jobs for millions of Americans, modernizing roads, airports, ports, and waterways all across America. \\n\\nAnd we’ll do it all to withstand the devastating effects of the climate crisis and promote environmental justice. \\n\\nWe’ll build a national network of 500,000 electric vehicle charging stations, begin to replace poisonous lead pipes—so every child—and every American—has clean water to drink at home and at school, provide affordable high-speed internet for every American—urban, suburban, rural, and tribal communities. \\n\\n4,000 projects have already been announced. \\n\\nAnd tonight, I’m announcing that this year we will start fixing over 65,000 miles of highway and 1,500 bridges in disrepair. \\n\\nWhen we use taxpayer dollars to rebuild America – we are going to Buy American: buy American products to support American jobs. \\n\\nThe federal government spends about $600 Billion a year to keep the country safe and secure. \\n\\nThere’s been a law on the books for almost a century \\nto make sure taxpayers’ dollars support American jobs and businesses. \\n\\nEvery Administration says they’ll do it, but we are actually doing it. \\n\\nWe will buy American to make sure everything from the deck of an aircraft carrier to the steel on highway guardrails are made in America. \\n\\nBut to compete for the best jobs of the future, we also need to level the playing field with China and other competitors. \\n\\nThat’s why it is so important to pass the Bipartisan Innovation Act sitting in Congress that will make record investments in emerging technologies and American manufacturing. \\n\\nLet me give you one example of why it’s so important to pass it. \\n\\nIf you travel 20 miles east of Columbus, Ohio, you’ll find 1,000 empty acres of land. \\n\\nIt won’t look like much, but if you stop and look closely, you’ll see a “Field of dreams,” the ground on which America’s future will be built. \\n\\nThis is where Intel, the American company that helped build Silicon Valley, is going to build its $20 billion semiconductor “mega site”. \\n\\nUp to eight state-of-the-art factories in one place. 10,000 new good-paying jobs. \\n\\nSome of the most sophisticated manufacturing in the world to make computer chips the size of a fingertip that power the world and our everyday lives. \\n\\nSmartphones. The Internet. Technology we have yet to invent. \\n\\nBut that’s just the beginning. \\n\\nIntel’s CEO, Pat Gelsinger, who is here tonight, told me they are ready to increase their investment from  \\n$20 billion to $100 billion. \\n\\nThat would be one of the biggest investments in manufacturing in American history. \\n\\nAnd all they’re waiting for is for you to pass this bill. \\n\\nSo let’s not wait any longer. Send it to my desk. I’ll sign it.  \\n\\nAnd we will really take off. \\n\\nAnd Intel is not alone. \\n\\nThere’s something happening in America. \\n\\nJust look around and you’ll see an amazing story. \\n\\nThe rebirth of the pride that comes from stamping products “Made In America.” The revitalization of American manufacturing.   \\n\\nCompanies are choosing to build new factories here, when just a few years ago, they would have built them overseas. \\n\\nThat’s what is happening. Ford is investing $11 billion to build electric vehicles, creating 11,000 jobs across the country. \\n\\nGM is making the largest investment in its history—$7 billion to build electric vehicles, creating 4,000 jobs in Michigan. \\n\\nAll told, we created 369,000 new manufacturing jobs in America just last year. \\n\\nPowered by people I’ve met like JoJo Burgess, from generations of union steelworkers from Pittsburgh, who’s here with us tonight. \\n\\nAs Ohio Senator Sherrod Brown says, “It’s time to bury the label “Rust Belt.” \\n\\nIt’s time. \\n\\nBut with all the bright spots in our economy, record job growth and higher wages, too many families are struggling to keep up with the bills.  \\n\\nInflation is robbing them of the gains they might otherwise feel. \\n\\nI get it. That’s why my top priority is getting prices under control. \\n\\nLook, our economy roared back faster than most predicted, but the pandemic meant that businesses had a hard time hiring enough workers to keep up production in their factories. \\n\\nThe pandemic also disrupted global supply chains. \\n\\nWhen factories close, it takes longer to make goods and get them from the warehouse to the store, and prices go up. \\n\\nLook at cars. \\n\\nLast year, there weren’t enough semiconductors to make all the cars that people wanted to buy. \\n\\nAnd guess what, prices of automobiles went up. \\n\\nSo—we have a choice. \\n\\nOne way to fight inflation is to drive down wages and make Americans poorer.  \\n\\nI have a better plan to fight inflation. \\n\\nLower your costs, not your wages. \\n\\nMake more cars and semiconductors in America. \\n\\nMore infrastructure and innovation in America. \\n\\nMore goods moving faster and cheaper in America. \\n\\nMore jobs where you can earn a good living in America. \\n\\nAnd instead of relying on foreign supply chains, let’s make it in America. \\n\\nEconomists call it “increasing the productive capacity of our economy.” \\n\\nI call it building a better America. \\n\\nMy plan to fight inflation will lower your costs and lower the deficit. \\n\\n17 Nobel laureates in economics say my plan will ease long-term inflationary pressures. Top business leaders and most Americans support my plan. And here’s the plan: \\n\\nFirst – cut the cost of prescription drugs. Just look at insulin. One in ten Americans has diabetes. In Virginia, I met a 13-year-old boy named Joshua Davis.  \\n\\nHe and his Dad both have Type 1 diabetes, which means they need insulin every day. Insulin costs about $10 a vial to make.  \\n\\nBut drug companies charge families like Joshua and his Dad up to 30 times more. I spoke with Joshua’s mom. \\n\\nImagine what it’s like to look at your child who needs insulin and have no idea how you’re going to pay for it.  \\n\\nWhat it does to your dignity, your ability to look your child in the eye, to be the parent you expect to be. \\n\\nJoshua is here with us tonight. Yesterday was his birthday. Happy birthday, buddy.  \\n\\nFor Joshua, and for the 200,000 other young people with Type 1 diabetes, let’s cap the cost of insulin at $35 a month so everyone can afford it.  \\n\\nDrug companies will still do very well. And while we’re at it let Medicare negotiate lower prices for prescription drugs, like the VA already does. \\n\\nLook, the American Rescue Plan is helping millions of families on Affordable Care Act plans save $2,400 a year on their health care premiums. Let’s close the coverage gap and make those savings permanent. \\n\\nSecond – cut energy costs for families an average of $500 a year by combatting climate change.  \\n\\nLet’s provide investments and tax credits to weatherize your homes and businesses to be energy efficient and you get a tax credit; double America’s clean energy production in solar, wind, and so much more;  lower the price of electric vehicles, saving you another $80 a month because you’ll never have to pay at the gas pump again. \\n\\nThird – cut the cost of child care. Many families pay up to $14,000 a year for child care per child.  \\n\\nMiddle-class and working families shouldn’t have to pay more than 7% of their income for care of young children.  \\n\\nMy plan will cut the cost in half for most families and help parents, including millions of women, who left the workforce during the pandemic because they couldn’t afford child care, to be able to get back to work. \\n\\nMy plan doesn’t stop there. It also includes home and long-term care. More affordable housing. And Pre-K for every 3- and 4-year-old.  \\n\\nAll of these will lower costs. \\n\\nAnd under my plan, nobody earning less than $400,000 a year will pay an additional penny in new taxes. Nobody.  \\n\\nThe one thing all Americans agree on is that the tax system is not fair. We have to fix it.  \\n\\nI’m not looking to punish anyone. But let’s make sure corporations and the wealthiest Americans start paying their fair share. \\n\\nJust last year, 55 Fortune 500 corporations earned $40 billion in profits and paid zero dollars in federal income tax.  \\n\\nThat’s simply not fair. That’s why I’ve proposed a 15% minimum tax rate for corporations. \\n\\nWe got more than 130 countries to agree on a global minimum tax rate so companies can’t get out of paying their taxes at home by shipping jobs and factories overseas. \\n\\nThat’s why I’ve proposed closing loopholes so the very wealthy don’t pay a lower tax rate than a teacher or a firefighter.  \\n\\nSo that’s my plan. It will grow the economy and lower costs for families. \\n\\nSo what are we waiting for? Let’s get this done. And while you’re at it, confirm my nominees to the Federal Reserve, which plays a critical role in fighting inflation.  \\n\\nMy plan will not only lower costs to give families a fair shot, it will lower the deficit. \\n\\nThe previous Administration not only ballooned the deficit with tax cuts for the very wealthy and corporations, it undermined the watchdogs whose job was to keep pandemic relief funds from being wasted. \\n\\nBut in my administration, the watchdogs have been welcomed back. \\n\\nWe’re going after the criminals who stole billions in relief money meant for small businesses and millions of Americans.  \\n\\nAnd tonight, I’m announcing that the Justice Department will name a chief prosecutor for pandemic fraud. \\n\\nBy the end of this year, the deficit will be down to less than half what it was before I took office.  \\n\\nThe only president ever to cut the deficit by more than one trillion dollars in a single year. \\n\\nLowering your costs also means demanding more competition. \\n\\nI’m a capitalist, but capitalism without competition isn’t capitalism. \\n\\nIt’s exploitation—and it drives up prices. \\n\\nWhen corporations don’t have to compete, their profits go up, your prices go up, and small businesses and family farmers and ranchers go under. \\n\\nWe see it happening with ocean carriers moving goods in and out of America. \\n\\nDuring the pandemic, these foreign-owned companies raised prices by as much as 1,000% and made record profits. \\n\\nTonight, I’m announcing a crackdown on these companies overcharging American businesses and consumers. \\n\\nAnd as Wall Street firms take over more nursing homes, quality in those homes has gone down and costs have gone up.  \\n\\nThat ends on my watch. \\n\\nMedicare is going to set higher standards for nursing homes and make sure your loved ones get the care they deserve and expect. \\n\\nWe’ll also cut costs and keep the economy going strong by giving workers a fair shot, provide more training and apprenticeships, hire them based on their skills not degrees. \\n\\nLet’s pass the Paycheck Fairness Act and paid leave.  \\n\\nRaise the minimum wage to $15 an hour and extend the Child Tax Credit, so no one has to raise a family in poverty. \\n\\nLet’s increase Pell Grants and increase our historic support of HBCUs, and invest in what Jill—our First Lady who teaches full-time—calls America’s best-kept secret: community colleges. \\n\\nAnd let’s pass the PRO Act when a majority of workers want to form a union—they shouldn’t be stopped.  \\n\\nWhen we invest in our workers, when we build the economy from the bottom up and the middle out together, we can do something we haven’t done in a long time: build a better America. \\n\\nFor more than two years, COVID-19 has impacted every decision in our lives and the life of the nation. \\n\\nAnd I know you’re tired, frustrated, and exhausted. \\n\\nBut I also know this. \\n\\nBecause of the progress we’ve made, because of your resilience and the tools we have, tonight I can say  \\nwe are moving forward safely, back to more normal routines.  \\n\\nWe’ve reached a new moment in the fight against COVID-19, with severe cases down to a level not seen since last July.  \\n\\nJust a few days ago, the Centers for Disease Control and Prevention—the CDC—issued new mask guidelines. \\n\\nUnder these new guidelines, most Americans in most of the country can now be mask free.   \\n\\nAnd based on the projections, more of the country will reach that point across the next couple of weeks. \\n\\nThanks to the progress we have made this past year, COVID-19 need no longer control our lives.  \\n\\nI know some are talking about “living with COVID-19”. Tonight – I say that we will never just accept living with COVID-19. \\n\\nWe will continue to combat the virus as we do other diseases. And because this is a virus that mutates and spreads, we will stay on guard. \\n\\nHere are four common sense steps as we move forward safely.  \\n\\nFirst, stay protected with vaccines and treatments. We know how incredibly effective vaccines are. If you’re vaccinated and boosted you have the highest degree of protection. \\n\\nWe will never give up on vaccinating more Americans. Now, I know parents with kids under 5 are eager to see a vaccine authorized for their children. \\n\\nThe scientists are working hard to get that done and we’ll be ready with plenty of vaccines when they do. \\n\\nWe’re also ready with anti-viral treatments. If you get COVID-19, the Pfizer pill reduces your chances of ending up in the hospital by 90%.  \\n\\nWe’ve ordered more of these pills than anyone in the world. And Pfizer is working overtime to get us 1 Million pills this month and more than double that next month.  \\n\\nAnd we’re launching the “Test to Treat” initiative so people can get tested at a pharmacy, and if they’re positive, receive antiviral pills on the spot at no cost.  \\n\\nIf you’re immunocompromised or have some other vulnerability, we have treatments and free high-quality masks. \\n\\nWe’re leaving no one behind or ignoring anyone’s needs as we move forward. \\n\\nAnd on testing, we have made hundreds of millions of tests available for you to order for free.   \\n\\nEven if you already ordered free tests tonight, I am announcing that you can order more from covidtests.gov starting next week. \\n\\nSecond – we must prepare for new variants. Over the past year, we’ve gotten much better at detecting new variants. \\n\\nIf necessary, we’ll be able to deploy new vaccines within 100 days instead of many more months or years.  \\n\\nAnd, if Congress provides the funds we need, we’ll have new stockpiles of tests, masks, and pills ready if needed. \\n\\nI cannot promise a new variant won’t come. But I can promise you we’ll do everything within our power to be ready if it does.  \\n\\nThird – we can end the shutdown of schools and businesses. We have the tools we need. \\n\\nIt’s time for Americans to get back to work and fill our great downtowns again.  People working from home can feel safe to begin to return to the office.   \\n\\nWe’re doing that here in the federal government. The vast majority of federal workers will once again work in person. \\n\\nOur schools are open. Let’s keep it that way. Our kids need to be in school. \\n\\nAnd with 75% of adult Americans fully vaccinated and hospitalizations down by 77%, most Americans can remove their masks, return to work, stay in the classroom, and move forward safely. \\n\\nWe achieved this because we provided free vaccines, treatments, tests, and masks. \\n\\nOf course, continuing this costs money. \\n\\nI will soon send Congress a request. \\n\\nThe vast majority of Americans have used these tools and may want to again, so I expect Congress to pass it quickly.   \\n\\nFourth, we will continue vaccinating the world.     \\n\\nWe’ve sent 475 Million vaccine doses to 112 countries, more than any other nation. \\n\\nAnd we won’t stop. \\n\\nWe have lost so much to COVID-19. Time with one another. And worst of all, so much loss of life. \\n\\nLet’s use this moment to reset. Let’s stop looking at COVID-19 as a partisan dividing line and see it for what it is: A God-awful disease.  \\n\\nLet’s stop seeing each other as enemies, and start seeing each other for who we really are: Fellow Americans.  \\n\\nWe can’t change how divided we’ve been. But we can change how we move forward—on COVID-19 and other issues we must face together. \\n\\nI recently visited the New York City Police Department days after the funerals of Officer Wilbert Mora and his partner, Officer Jason Rivera. \\n\\nThey were responding to a 9-1-1 call when a man shot and killed them with a stolen gun. \\n\\nOfficer Mora was 27 years old. \\n\\nOfficer Rivera was 22. \\n\\nBoth Dominican Americans who’d grown up on the same streets they later chose to patrol as police officers. \\n\\nI spoke with their families and told them that we are forever in debt for their sacrifice, and we will carry on their mission to restore the trust and safety every community deserves. \\n\\nI’ve worked on these issues a long time. \\n\\nI know what works: Investing in crime preventionand community police officers who’ll walk the beat, who’ll know the neighborhood, and who can restore trust and safety. \\n\\nSo let’s not abandon our streets. Or choose between safety and equal justice. \\n\\nLet’s come together to protect our communities, restore trust, and hold law enforcement accountable. \\n\\nThat’s why the Justice Department required body cameras, banned chokeholds, and restricted no-knock warrants for its officers. \\n\\nThat’s why the American Rescue Plan provided $350 Billion that cities, states, and counties can use to hire more police and invest in proven strategies like community violence interruption—trusted messengers breaking the cycle of violence and trauma and giving young people hope.  \\n\\nWe should all agree: The answer is not to Defund the police. The answer is to FUND the police with the resources and training they need to protect our communities. \\n\\nI ask Democrats and Republicans alike: Pass my budget and keep our neighborhoods safe.  \\n\\nAnd I will keep doing everything in my power to crack down on gun trafficking and ghost guns you can buy online and make at home—they have no serial numbers and can’t be traced. \\n\\nAnd I ask Congress to pass proven measures to reduce gun violence. Pass universal background checks. Why should anyone on a terrorist list be able to purchase a weapon? \\n\\nBan assault weapons and high-capacity magazines. \\n\\nRepeal the liability shield that makes gun manufacturers the only industry in America that can’t be sued. \\n\\nThese laws don’t infringe on the Second Amendment. They save lives. \\n\\nThe most fundamental right in America is the right to vote – and to have it counted. And it’s under assault. \\n\\nIn state after state, new laws have been passed, not only to suppress the vote, but to subvert entire elections. \\n\\nWe cannot let this happen. \\n\\nTonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you’re at it, pass the Disclose Act so Americans can know who is funding our elections. \\n\\nTonight, I’d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer—an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \\n\\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \\n\\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence. \\n\\nA former top litigator in private practice. A former federal public defender. And from a family of public school educators and police officers. A consensus builder. Since she’s been nominated, she’s received a broad range of support—from the Fraternal Order of Police to former judges appointed by Democrats and Republicans. \\n\\nAnd if we are to advance liberty and justice, we need to secure the Border and fix the immigration system. \\n\\nWe can do both. At our border, we’ve installed new technology like cutting-edge scanners to better detect drug smuggling.  \\n\\nWe’ve set up joint patrols with Mexico and Guatemala to catch more human traffickers.  \\n\\nWe’re putting in place dedicated immigration judges so families fleeing persecution and violence can have their cases heard faster. \\n\\nWe’re securing commitments and supporting partners in South and Central America to host more refugees and secure their own borders. \\n\\nWe can do all this while keeping lit the torch of liberty that has led generations of immigrants to this land—my forefathers and so many of yours. \\n\\nProvide a pathway to citizenship for Dreamers, those on temporary status, farm workers, and essential workers. \\n\\nRevise our laws so businesses have the workers they need and families don’t wait decades to reunite. \\n\\nIt’s not only the right thing to do—it’s the economically smart thing to do. \\n\\nThat’s why immigration reform is supported by everyone from labor unions to religious leaders to the U.S. Chamber of Commerce. \\n\\nLet’s get it done once and for all. \\n\\nAdvancing liberty and justice also requires protecting the rights of women. \\n\\nThe constitutional right affirmed in Roe v. Wade—standing precedent for half a century—is under attack as never before. \\n\\nIf we want to go forward—not backward—we must protect access to health care. Preserve a woman’s right to choose. And let’s continue to advance maternal health care in America. \\n\\nAnd for our LGBTQ+ Americans, let’s finally get the bipartisan Equality Act to my desk. The onslaught of state laws targeting transgender Americans and their families is wrong. \\n\\nAs I said last year, especially to our younger transgender Americans, I will always have your back as your President, so you can be yourself and reach your God-given potential. \\n\\nWhile it often appears that we never agree, that isn’t true. I signed 80 bipartisan bills into law last year. From preventing government shutdowns to protecting Asian-Americans from still-too-common hate crimes to reforming military justice. \\n\\nAnd soon, we’ll strengthen the Violence Against Women Act that I first wrote three decades ago. It is important for us to show the nation that we can come together and do big things. \\n\\nSo tonight I’m offering a Unity Agenda for the Nation. Four big things we can do together.  \\n\\nFirst, beat the opioid epidemic. \\n\\nThere is so much we can do. Increase funding for prevention, treatment, harm reduction, and recovery.  \\n\\nGet rid of outdated rules that stop doctors from prescribing treatments. And stop the flow of illicit drugs by working with state and local law enforcement to go after traffickers. \\n\\nIf you’re suffering from addiction, know you are not alone. I believe in recovery, and I celebrate the 23 million Americans in recovery. \\n\\nSecond, let’s take on mental health. Especially among our children, whose lives and education have been turned upside down.  \\n\\nThe American Rescue Plan gave schools money to hire teachers and help students make up for lost learning.  \\n\\nI urge every parent to make sure your school does just that. And we can all play a part—sign up to be a tutor or a mentor. \\n\\nChildren were also struggling before the pandemic. Bullying, violence, trauma, and the harms of social media. \\n\\nAs Frances Haugen, who is here with us tonight, has shown, we must hold social media platforms accountable for the national experiment they’re conducting on our children for profit. \\n\\nIt’s time to strengthen privacy protections, ban targeted advertising to children, demand tech companies stop collecting personal data on our children. \\n\\nAnd let’s get all Americans the mental health services they need. More people they can turn to for help, and full parity between physical and mental health care. \\n\\nThird, support our veterans. \\n\\nVeterans are the best of us. \\n\\nI’ve always believed that we have a sacred obligation to equip all those we send to war and care for them and their families when they come home. \\n\\nMy administration is providing assistance with job training and housing, and now helping lower-income veterans get VA care debt-free.  \\n\\nOur troops in Iraq and Afghanistan faced many dangers. \\n\\nOne was stationed at bases and breathing in toxic smoke from “burn pits” that incinerated wastes of war—medical and hazard material, jet fuel, and more. \\n\\nWhen they came home, many of the world’s fittest and best trained warriors were never the same. \\n\\nHeadaches. Numbness. Dizziness. \\n\\nA cancer that would put them in a flag-draped coffin. \\n\\nI know. \\n\\nOne of those soldiers was my son Major Beau Biden. \\n\\nWe don’t know for sure if a burn pit was the cause of his brain cancer, or the diseases of so many of our troops. \\n\\nBut I’m committed to finding out everything we can. \\n\\nCommitted to military families like Danielle Robinson from Ohio. \\n\\nThe widow of Sergeant First Class Heath Robinson.  \\n\\nHe was born a soldier. Army National Guard. Combat medic in Kosovo and Iraq. \\n\\nStationed near Baghdad, just yards from burn pits the size of football fields. \\n\\nHeath’s widow Danielle is here with us tonight. They loved going to Ohio State football games. He loved building Legos with their daughter. \\n\\nBut cancer from prolonged exposure to burn pits ravaged Heath’s lungs and body. \\n\\nDanielle says Heath was a fighter to the very end. \\n\\nHe didn’t know how to stop fighting, and neither did she. \\n\\nThrough her pain she found purpose to demand we do better. \\n\\nTonight, Danielle—we are. \\n\\nThe VA is pioneering new ways of linking toxic exposures to diseases, already helping more veterans get benefits. \\n\\nAnd tonight, I’m announcing we’re expanding eligibility to veterans suffering from nine respiratory cancers. \\n\\nI’m also calling on Congress: pass a law to make sure veterans devastated by toxic exposures in Iraq and Afghanistan finally get the benefits and comprehensive health care they deserve. \\n\\nAnd fourth, let’s end cancer as we know it. \\n\\nThis is personal to me and Jill, to Kamala, and to so many of you. \\n\\nCancer is the #2 cause of death in America–second only to heart disease. \\n\\nLast month, I announced our plan to supercharge  \\nthe Cancer Moonshot that President Obama asked me to lead six years ago. \\n\\nOur goal is to cut the cancer death rate by at least 50% over the next 25 years, turn more cancers from death sentences into treatable diseases.  \\n\\nMore support for patients and families. \\n\\nTo get there, I call on Congress to fund ARPA-H, the Advanced Research Projects Agency for Health. \\n\\nIt’s based on DARPA—the Defense Department project that led to the Internet, GPS, and so much more.  \\n\\nARPA-H will have a singular purpose—to drive breakthroughs in cancer, Alzheimer’s, diabetes, and more. \\n\\nA unity agenda for the nation. \\n\\nWe can do this. \\n\\nMy fellow Americans—tonight , we have gathered in a sacred space—the citadel of our democracy. \\n\\nIn this Capitol, generation after generation, Americans have debated great questions amid great strife, and have done great things. \\n\\nWe have fought for freedom, expanded liberty, defeated totalitarianism and terror. \\n\\nAnd built the strongest, freest, and most prosperous nation the world has ever known. \\n\\nNow is the hour. \\n\\nOur moment of responsibility. \\n\\nOur test of resolve and conscience, of history itself. \\n\\nIt is in this moment that our character is formed. Our purpose is found. Our future is forged. \\n\\nWell I know this nation.  \\n\\nWe will meet the test. \\n\\nTo protect freedom and liberty, to expand fairness and opportunity. \\n\\nWe will save democracy. \\n\\nAs hard as these times have been, I am more optimistic about America today than I have been my whole life. \\n\\nBecause I see the future that is within our grasp. \\n\\nBecause I know there is simply nothing beyond our capacity. \\n\\nWe are the only nation on Earth that has always turned every crisis we have faced into an opportunity. \\n\\nThe only nation that can be defined by a single word: possibilities. \\n\\nSo on this night, in our 245th year as a nation, I have come to report on the State of the Union. \\n\\nAnd my report is this: the State of the Union is strong—because you, the American people, are strong. \\n\\nWe are stronger today than we were a year ago. \\n\\nAnd we will be stronger a year from now than we are today. \\n\\nNow is our moment to meet and overcome the challenges of our time. \\n\\nAnd we will, as one people. \\n\\nOne America. \\n\\nThe United States of America. \\n\\nMay God bless you all. May God protect our troops.', metadata={'source': 'data_input/state_of_the_union.txt'})]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the document has been loaded, we may find that it consists of multiple paragraphs. To facilitate our search for the most relevant paragraph, we can use the `CharacterTextSplitter` module. By specifying the `chunk_size` parameter as 1000 characters and setting `chunk_overlap` to 0, the document will be divided into smaller chunks or segments, each containing approximately 1000 characters.\n",
    "\n",
    "This splitting process allows us to analyze each paragraph individually and determine which one is most similar to our query. It simplifies the task of finding relevant information within the document and enables more focused analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Madam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and the Cabinet. Justices of the Supreme Court. My fellow Americans.  \\n\\nLast year COVID-19 kept us apart. This year we are finally together again. \\n\\nTonight, we meet as Democrats Republicans and Independents. But most importantly as Americans. \\n\\nWith a duty to one another to the American people to the Constitution. \\n\\nAnd with an unwavering resolve that freedom will always triumph over tyranny. \\n\\nSix days ago, Russia’s Vladimir Putin sought to shake the foundations of the free world thinking he could make it bend to his menacing ways. But he badly miscalculated. \\n\\nHe thought he could roll into Ukraine and the world would roll over. Instead he met a wall of strength he never imagined. \\n\\nHe met the Ukrainian people. \\n\\nFrom President Zelenskyy to every Ukrainian, their fearlessness, their courage, their determination, inspires the world.', metadata={'source': 'data_input/state_of_the_union.txt'}),\n",
       " Document(page_content='Groups of citizens blocking tanks with their bodies. Everyone from students to retirees teachers turned soldiers defending their homeland. \\n\\nIn this struggle as President Zelenskyy said in his speech to the European Parliament “Light will win over darkness.” The Ukrainian Ambassador to the United States is here tonight. \\n\\nLet each of us here tonight in this Chamber send an unmistakable signal to Ukraine and to the world. \\n\\nPlease rise if you are able and show that, Yes, we the United States of America stand with the Ukrainian people. \\n\\nThroughout our history we’ve learned this lesson when dictators do not pay a price for their aggression they cause more chaos.   \\n\\nThey keep moving.   \\n\\nAnd the costs and the threats to America and the world keep rising.   \\n\\nThat’s why the NATO Alliance was created to secure peace and stability in Europe after World War 2. \\n\\nThe United States is a member along with 29 other nations. \\n\\nIt matters. American diplomacy matters. American resolve matters.', metadata={'source': 'data_input/state_of_the_union.txt'}),\n",
       " Document(page_content='Putin’s latest attack on Ukraine was premeditated and unprovoked. \\n\\nHe rejected repeated efforts at diplomacy. \\n\\nHe thought the West and NATO wouldn’t respond. And he thought he could divide us at home. Putin was wrong. We were ready.  Here is what we did.   \\n\\nWe prepared extensively and carefully. \\n\\nWe spent months building a coalition of other freedom-loving nations from Europe and the Americas to Asia and Africa to confront Putin. \\n\\nI spent countless hours unifying our European allies. We shared with the world in advance what we knew Putin was planning and precisely how he would try to falsely justify his aggression.  \\n\\nWe countered Russia’s lies with truth.   \\n\\nAnd now that he has acted the free world is holding him accountable. \\n\\nAlong with twenty-seven members of the European Union including France, Germany, Italy, as well as countries like the United Kingdom, Canada, Japan, Korea, Australia, New Zealand, and many others, even Switzerland.', metadata={'source': 'data_input/state_of_the_union.txt'})]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split it into chunks\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "text = text_splitter.split_documents(document)\n",
    "\n",
    "text[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have split each paragraph in the document, we can proceed to embed the sentences and store them in Chroma for efficient retrieval.\n",
    "\n",
    "- We will create an open-source embedding function using `SentenceTransformerEmbeddings`. In this example, we use the model \"all-MiniLM-L6-v2\" to perform the sentence embedding.\n",
    "\n",
    "- We load the embedded sentences into Chroma using the `from_documents` method. We pass in the `text` as the input and the `embedding_function` to perform the embedding process. Chroma will store the embedded vectors along with their corresponding sentences, enabling fast and accurate retrieval based on semantic similarity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the open-source embedding function\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# load it into Chroma\n",
    "db = Chroma.from_documents(text, embedding_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By leveraging Chroma, we can easily search for the most relevant sentences or paragraphs in the document by comparing their embedded vectors, providing a powerful tool for text processing and information retrieval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chroma will store the extracted ids, embeddings, documents, and metadata into a collection. This collection acts as a repository where the information is organized and indexed for efficient retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ids', 'embeddings', 'documents', 'metadatas'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db._collection.get().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The `ids` represent unique identifiers associated with each document or sentence in the collection. These ids serve as references to access specific entries in the collection.\n",
    "\n",
    "- The `embeddings` are the vector representations of the documents or sentences. These embeddings capture the semantic information and enable similarity-based searches within the collection.\n",
    "\n",
    "- The `documents` refer to the original text content that has been split and processed. These documents can be paragraphs, sentences, or any other meaningful textual units.\n",
    "\n",
    "- The `metadata` includes any additional information associated with the documents, such as timestamps, author names, or any other relevant attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Madam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and the Cabinet. Justices of the Supreme Court. My fellow Americans.  \\n\\nLast year COVID-19 kept us apart. This year we are finally together again. \\n\\nTonight, we meet as Democrats Republicans and Independents. But most importantly as Americans. \\n\\nWith a duty to one another to the American people to the Constitution. \\n\\nAnd with an unwavering resolve that freedom will always triumph over tyranny. \\n\\nSix days ago, Russia’s Vladimir Putin sought to shake the foundations of the free world thinking he could make it bend to his menacing ways. But he badly miscalculated. \\n\\nHe thought he could roll into Ukraine and the world would roll over. Instead he met a wall of strength he never imagined. \\n\\nHe met the Ukrainian people. \\n\\nFrom President Zelenskyy to every Ukrainian, their fearlessness, their courage, their determination, inspires the world.',\n",
       " 'A former top litigator in private practice. A former federal public defender. And from a family of public school educators and police officers. A consensus builder. Since she’s been nominated, she’s received a broad range of support—from the Fraternal Order of Police to former judges appointed by Democrats and Republicans. \\n\\nAnd if we are to advance liberty and justice, we need to secure the Border and fix the immigration system. \\n\\nWe can do both. At our border, we’ve installed new technology like cutting-edge scanners to better detect drug smuggling.  \\n\\nWe’ve set up joint patrols with Mexico and Guatemala to catch more human traffickers.  \\n\\nWe’re putting in place dedicated immigration judges so families fleeing persecution and violence can have their cases heard faster. \\n\\nWe’re securing commitments and supporting partners in South and Central America to host more refugees and secure their own borders.',\n",
       " 'Putin’s latest attack on Ukraine was premeditated and unprovoked. \\n\\nHe rejected repeated efforts at diplomacy. \\n\\nHe thought the West and NATO wouldn’t respond. And he thought he could divide us at home. Putin was wrong. We were ready.  Here is what we did.   \\n\\nWe prepared extensively and carefully. \\n\\nWe spent months building a coalition of other freedom-loving nations from Europe and the Americas to Asia and Africa to confront Putin. \\n\\nI spent countless hours unifying our European allies. We shared with the world in advance what we knew Putin was planning and precisely how he would try to falsely justify his aggression.  \\n\\nWe countered Russia’s lies with truth.   \\n\\nAnd now that he has acted the free world is holding him accountable. \\n\\nAlong with twenty-seven members of the European Union including France, Germany, Italy, as well as countries like the United Kingdom, Canada, Japan, Korea, Australia, New Zealand, and many others, even Switzerland.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db._collection.get()['documents'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['f6cba890-2abc-11ee-a5ab-acde48001122',\n",
       " 'f6cbaf52-2abc-11ee-a5ab-acde48001122',\n",
       " 'f6cbaa0c-2abc-11ee-a5ab-acde48001122']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db._collection.get()['ids'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'source': 'data_input/state_of_the_union.txt'},\n",
       " {'source': 'data_input/state_of_the_union.txt'},\n",
       " {'source': 'data_input/state_of_the_union.txt'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db._collection.get()['metadatas'][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After exploring the Chroma collection and embedding the query, we can evaluate the performance of our model by finding similar documents that best match the given question.\n",
    "\n",
    "We will define the `query` as \"What did the president say about Ketanji Brown Jackson\" and use the `similarity_search_with_score` function from Chroma to find the most similar documents to the query. We specify `k=3` to retrieve the top 3 matching documents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed query and find similar document\n",
    "query = \"What did the president say about Ketanji Brown Jackson\"\n",
    "docs = db.similarity_search_with_score(query, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(page_content='Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you’re at it, pass the Disclose Act so Americans can know who is funding our elections. \\n\\nTonight, I’d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer—an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \\n\\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \\n\\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence.', metadata={'source': 'data_input/state_of_the_union.txt'}),\n",
       "  1.1972051858901978),\n",
       " (Document(page_content='A former top litigator in private practice. A former federal public defender. And from a family of public school educators and police officers. A consensus builder. Since she’s been nominated, she’s received a broad range of support—from the Fraternal Order of Police to former judges appointed by Democrats and Republicans. \\n\\nAnd if we are to advance liberty and justice, we need to secure the Border and fix the immigration system. \\n\\nWe can do both. At our border, we’ve installed new technology like cutting-edge scanners to better detect drug smuggling.  \\n\\nWe’ve set up joint patrols with Mexico and Guatemala to catch more human traffickers.  \\n\\nWe’re putting in place dedicated immigration judges so families fleeing persecution and violence can have their cases heard faster. \\n\\nWe’re securing commitments and supporting partners in South and Central America to host more refugees and secure their own borders.', metadata={'source': 'data_input/state_of_the_union.txt'}),\n",
       "  1.6858735084533691),\n",
       " (Document(page_content='We can do all this while keeping lit the torch of liberty that has led generations of immigrants to this land—my forefathers and so many of yours. \\n\\nProvide a pathway to citizenship for Dreamers, those on temporary status, farm workers, and essential workers. \\n\\nRevise our laws so businesses have the workers they need and families don’t wait decades to reunite. \\n\\nIt’s not only the right thing to do—it’s the economically smart thing to do. \\n\\nThat’s why immigration reform is supported by everyone from labor unions to religious leaders to the U.S. Chamber of Commerce. \\n\\nLet’s get it done once and for all. \\n\\nAdvancing liberty and justice also requires protecting the rights of women. \\n\\nThe constitutional right affirmed in Roe v. Wade—standing precedent for half a century—is under attack as never before. \\n\\nIf we want to go forward—not backward—we must protect access to health care. Preserve a woman’s right to choose. And let’s continue to advance maternal health care in America.', metadata={'source': 'data_input/state_of_the_union.txt'}),\n",
       "  1.686741828918457)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of this operation will provide us with a 5 list of documents along with their similarity scores, indicating how closely they match the query. The higher the score, the more relevant the document is to the given question. This allows us to assess the performance of our model in retrieving relevant information based on the input query.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we have a collection of text files stored in a folder and we want to embed each of them? We can achieve this by using the `DirectoryLoader` to load all the files in the directory as documents. Then, we can split each paragraph within the documents using the `RecursiveCharacterTextSplitter` to prepare the text for embedding.\n",
    "\n",
    "The `DirectoryLoader` allows us to conveniently load all the files in a directory, while the `RecursiveCharacterTextSplitter` enables us to split the text into smaller chunks, such as paragraphs, for further processing. This combination of loaders and text splitters helps us prepare the data for embedding and subsequent analysis or retrieval tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use `DirectoryLoader` to load text files from a specific directory (`data_input/new_articles/`) using the `TextLoader` class. It will load all the files with the `.txt` extension in the specified directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process the all text files in new_articles\n",
    "loader = DirectoryLoader('data_input/new_articles/', glob=\"./*.txt\", loader_cls=TextLoader)\n",
    "\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To handle the multiple text files, we use the `RecursiveCharacterTextSplitter` to split the text into smaller chunks. This allows us to process each file efficiently and perform further analysis or tasks on the split text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the text into\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "text = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, it will split the text into chunks of 1000 characters with an overlap of 200 characters between consecutive chunks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='ChatGPT: Everything you need to know about the AI-powered chatbot\\n\\nChatGPT, OpenAI’s text-generating AI chatbot, has taken the world by storm. It’s able to write essays, code and more given short text prompts, hyper-charging productivity. But it also has a more…nefarious side.\\n\\nIn any case, AI tools are not going away — and indeed has expanded dramatically since its launch just a few months ago. Major brands are experimenting with it, using the AI to generate ad and marketing copy, for example.\\n\\nAnd OpenAI is heavily investing in it. ChatGPT was recently super-charged by GPT-4, the latest language-writing model from OpenAI’s labs. Paying ChatGPT users have access to GPT-4, which can write more naturally and fluently than the model that previously powered ChatGPT. In addition to GPT-4, OpenAI recently connected ChatGPT to the internet with plugins available in alpha to users and developers on the waitlist.', metadata={'source': 'data_input/new_articles/05-03-chatgpt-everything-you-need-to-know-about-the-ai-powered-chatbot.txt'}),\n",
       " Document(page_content='Here’s a timeline of ChatGPT product updates and releases, starting with the latest, to be updated regularly. We also answer the most common FAQs (see below).\\n\\nTimeline of the most recent ChatGPT updates\\n\\nMay 3, 2023\\n\\nMeta said in a report on May 3 that malware posing as ChatGPT was on the rise across its platforms.The company said that since March 2023, its security teams have uncovered 10 malware families using ChatGPT (and similar themes) to deliver malicious software to users’ devices.\\n\\n“In one case, we’ve seen threat actors create malicious browser extensions available in official web stores that claim to offer ChatGPT-based tools,” said Meta security engineers Duc H. Nguyen and Ryan Victory in a blog post. “They would then promote these malicious extensions on social media and through sponsored search results to trick people into downloading malware.”\\n\\nApril 28, 2023', metadata={'source': 'data_input/new_articles/05-03-chatgpt-everything-you-need-to-know-about-the-ai-powered-chatbot.txt'}),\n",
       " Document(page_content='April 28, 2023\\n\\nVC firms including Sequoia Capital, Andreessen Horowitz, Thrive and K2 Global are picking up new shares, according to documents seen by TechCrunch. A source tells us Founders Fund is also investing. Altogether the VCs have put in just over $300 million at a valuation of $27 billion to $29 billion. This is separate to a big investment from Microsoft announced earlier this year, a person familiar with the development told TechCrunch, which closed in January. The size of Microsoft’s investment is believed to be around $10 billion, a figure we confirmed with our source.\\n\\nApril 25, 2023\\n\\nCalled ChatGPT Business, OpenAI describes the forthcoming offering as “for professionals who need more control over their data as well as enterprises seeking to manage their end users.”', metadata={'source': 'data_input/new_articles/05-03-chatgpt-everything-you-need-to-know-about-the-ai-powered-chatbot.txt'})]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have split all our text. The following steps is same like the code before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(page_content='Pando was co-launched by Jayakrishnan and Abhijeet Manohar, who previously worked together at iDelivery, an India-based freight tech marketplace — and their first startup. The two saw firsthand manufacturers, distributors and retailers were struggling with legacy tech and point solutions to understand, optimize and manage their global logistics operations — or at least, that’s the story Jayakrishnan tells.\\n\\n“Supply chain leaders were trying to build their own tech and throwing people at the problem,” he said. “This caught our attention — we spent months talking to and building for enterprise users at warehouses, factories, freight yards and ports and eventually, in 2018, decided to start Pando to solve for global logistics through a software-as-a-service platform offering.”', metadata={'source': 'data_input/new_articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt'}),\n",
       "  0.9159137010574341),\n",
       " (Document(page_content='Signaling that investments in the supply chain sector remain robust, Pando, a startup developing fulfillment management technologies, today announced that it raised $30 million in a Series B round, bringing its total raised to $45 million.\\n\\nIron Pillar and Uncorrelated Ventures led the round, with participation from existing investors Nexus Venture Partners, Chiratae Ventures and Next47. CEO and founder Nitin Jayakrishnan says that the new capital will be put toward expanding Pando’s global sales, marketing and delivery capabilities.\\n\\n“We will not expand into new industries or adjacent product areas,” he told TechCrunch in an email interview. “Great talent is the foundation of the business — we will continue to augment our teams at all levels of the organization. Pando is also open to exploring strategic partnerships and acquisitions with this round of funding.”', metadata={'source': 'data_input/new_articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt'}),\n",
       "  0.9696444272994995),\n",
       " (Document(page_content='The result of those major disruptions? The digital logistics market is estimated to climb to $46.5 billion by 2025, per Markets and Markets — up from $17.4 billion in 2019. Crunchbase reports that investors poured more than $7 billion in seed through growth-stage rounds globally for supply chain-focused startups from January to October 2022, nearly eclipsing 2021’s record-setting levels.\\n\\n“Pando has a strong balance sheet and profit and loss statement, with an eye on profitable growth,” Jayakrishnan said. “We’re are scaling operations in North America, Europe and India with marquee customer wins and a network of strong partners … Pando is well-positioned to ride this growth wave, and drive supply chain agility for the 2030 economy.”', metadata={'source': 'data_input/new_articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt'}),\n",
       "  1.045091986656189),\n",
       " (Document(page_content='But Pando has a compelling sales pitch, judging by its momentum. The company counts Fortune 500 manufacturers and retailers — including P&G, J&J, Valvoline, Castrol, Cummins, Siemens, Danaher and Accuride — among its customer base. Since the startup’s Series A in 2020, revenue has grown 8x while the number of customers has increased 5x, Jayakrishnan said.\\n\\nAsked whether he expects expansion to continue well into the future, given the signs of potential trouble on the horizon, Jayakrishnan seemed fairly optimistic. He pointed to a Deloitte survey that found that more than 70% of manufacturing companies have been impacted by supply chain disruptions in the past year, with 90% of those companies experiencing increased costs and declining productivity.', metadata={'source': 'data_input/new_articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt'}),\n",
       "  1.1687313318252563)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the open-source embedding function\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# load it into Chroma\n",
    "vectordb = Chroma.from_documents(text, embedding_function)\n",
    "\n",
    "# query it\n",
    "query = \"What is the news about Pando?\"\n",
    "docs = vectordb.similarity_search_with_score(query)\n",
    "\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output variable contains the result of the similarity search performed on the `vectordb` using the query \"What is the news about Pando?\". It provides a ranked list of documents that have the highest similarity to the query, along with their similarity scores.\n",
    "\n",
    "By examining the `docs` list, we can see which documents are considered most relevant to the query based on their similarity scores. The **higher** the similarity score, the **more similar** the document is to the query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving to Disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding text can be a time-consuming and resource-intensive process, especially when dealing with a large amount of text data.\n",
    "\n",
    "To address this issue, we have the option to save our vector database, including the vectorized sentences, to disk. This allows us to load the saved vector database instead of re-embedding the text every time we need to use it.\n",
    "\n",
    "To save the vector database to disk, we simply initialize the Chroma client and specify the directory where we want the data to be saved.\n",
    "\n",
    "> **Caution**: Chroma makes a best-effort to automatically save data to disk, however multiple in-memory clients can stomp each other's work. As a best practice, only have one client per path running at any given time.\n",
    "\n",
    "> **Protip**: Sometimes we can use `db.persist()` to force a save if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to disk\n",
    "# load it into Chroma\n",
    "vectordb = Chroma.from_documents(text, embedding_function, persist_directory=\"./chroma_db\")\n",
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vector database will be saved in the `\"./chroma_db\"` folder. Whenever we want to use the embedded vectors, we can simply load them from the `\".chroma_db\"` file.\n",
    "\n",
    "To achieve this, we create the vector database using `Chroma.from_documents(text, embedding_function, persist_directory=\"./chroma_db\")`. The `persist_directory` parameter specifies the directory where the vector database will be saved.\n",
    "\n",
    "To ensure that the vector database is saved to disk, we call `vectordb.persist()`. This command forces the vector database to be saved in the specified directory.\n",
    "\n",
    "By saving the vector database to disk, we can easily load it whenever we need to use the embedded vectors, eliminating the need for repetitive embedding computations.\n",
    "\n",
    "Let's see how to load saved vector db in Chroma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(page_content='Pando was co-launched by Jayakrishnan and Abhijeet Manohar, who previously worked together at iDelivery, an India-based freight tech marketplace — and their first startup. The two saw firsthand manufacturers, distributors and retailers were struggling with legacy tech and point solutions to understand, optimize and manage their global logistics operations — or at least, that’s the story Jayakrishnan tells.\\n\\n“Supply chain leaders were trying to build their own tech and throwing people at the problem,” he said. “This caught our attention — we spent months talking to and building for enterprise users at warehouses, factories, freight yards and ports and eventually, in 2018, decided to start Pando to solve for global logistics through a software-as-a-service platform offering.”', metadata={'source': 'data_input/new_articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt'}),\n",
       "  0.9159137010574341),\n",
       " (Document(page_content='Signaling that investments in the supply chain sector remain robust, Pando, a startup developing fulfillment management technologies, today announced that it raised $30 million in a Series B round, bringing its total raised to $45 million.\\n\\nIron Pillar and Uncorrelated Ventures led the round, with participation from existing investors Nexus Venture Partners, Chiratae Ventures and Next47. CEO and founder Nitin Jayakrishnan says that the new capital will be put toward expanding Pando’s global sales, marketing and delivery capabilities.\\n\\n“We will not expand into new industries or adjacent product areas,” he told TechCrunch in an email interview. “Great talent is the foundation of the business — we will continue to augment our teams at all levels of the organization. Pando is also open to exploring strategic partnerships and acquisitions with this round of funding.”', metadata={'source': 'data_input/new_articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt'}),\n",
       "  0.9696444272994995),\n",
       " (Document(page_content='The result of those major disruptions? The digital logistics market is estimated to climb to $46.5 billion by 2025, per Markets and Markets — up from $17.4 billion in 2019. Crunchbase reports that investors poured more than $7 billion in seed through growth-stage rounds globally for supply chain-focused startups from January to October 2022, nearly eclipsing 2021’s record-setting levels.\\n\\n“Pando has a strong balance sheet and profit and loss statement, with an eye on profitable growth,” Jayakrishnan said. “We’re are scaling operations in North America, Europe and India with marquee customer wins and a network of strong partners … Pando is well-positioned to ride this growth wave, and drive supply chain agility for the 2030 economy.”', metadata={'source': 'data_input/new_articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt'}),\n",
       "  1.045091986656189),\n",
       " (Document(page_content='But Pando has a compelling sales pitch, judging by its momentum. The company counts Fortune 500 manufacturers and retailers — including P&G, J&J, Valvoline, Castrol, Cummins, Siemens, Danaher and Accuride — among its customer base. Since the startup’s Series A in 2020, revenue has grown 8x while the number of customers has increased 5x, Jayakrishnan said.\\n\\nAsked whether he expects expansion to continue well into the future, given the signs of potential trouble on the horizon, Jayakrishnan seemed fairly optimistic. He pointed to a Deloitte survey that found that more than 70% of manufacturing companies have been impacted by supply chain disruptions in the past year, with 90% of those companies experiencing increased costs and declining productivity.', metadata={'source': 'data_input/new_articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt'}),\n",
       "  1.1687313318252563)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectordb_load = Chroma(persist_directory=\"./chroma_db\", embedding_function=embedding_function)\n",
    "\n",
    "# query it\n",
    "query = \"What is the news about Pando?\"\n",
    "docs_load = vectordb_load.similarity_search_with_score(query)\n",
    "\n",
    "docs_load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code is loading the vector database from the \"./chroma_db\" directory using the `Chroma` class with the `persist_directory` parameter set to the same directory where the vector database was previously saved. The `embedding_function` is also provided to ensure consistency in embedding.\n",
    "\n",
    "After loading the vector database, a query is performed by specifying the query sentence as \"What is the news about Pando?\". The `similarity_search_with_score` method is used to find the most similar documents in the vector database based on the query. \n",
    "\n",
    "The output, `docs_load`, contains the results of the query, which typically include the most relevant documents along with their similarity scores. These documents are ranked based on their similarity to the query, with higher scores indicating greater similarity. The exact format of the output depends on the implementation, but it usually includes information such as document IDs, similarity scores, and potentially other metadata associated with the documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow: Applications of Embedding in Text Processing with Large Language Models (LLM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create QnA System from Vector Database\n",
    "\n",
    "In this section, we will explain the workflow to create a Q&A system by leveraging a vector database and the power of LangChain and Chroma DB. This workflow will serve as a guide for building similar projects and can be adapted for various text processing tasks, including summarized text analysis, document retrieval, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding and Vector Database Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will utilize the previously embedded data that was stored on disk. The Chroma database is loaded from the disk, and this is indicated by the `persist_directory` parameter set to \"./chroma_db\". Loading the Chroma database from the specified directory allows us to efficiently reuse the embeddings that were computed earlier. This avoids the need to recompute the embeddings, which saves time and computational resources, making our text processing workflow more efficient and faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "vectordb_load = Chroma(persist_directory=\"./chroma_db\", embedding_function=embedding_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will perform query processing by defining a question, and then we will find the most relevant answers using `vectordb_load.similarity_search`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask a question using the QA chain\n",
    "question = \"What is Pando vision?\"\n",
    "similar_docs = vectordb_load.similarity_search(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Pando was co-launched by Jayakrishnan and Abhijeet Manohar, who previously worked together at iDelivery, an India-based freight tech marketplace — and their first startup. The two saw firsthand manufacturers, distributors and retailers were struggling with legacy tech and point solutions to understand, optimize and manage their global logistics operations — or at least, that’s the story Jayakrishnan tells.\\n\\n“Supply chain leaders were trying to build their own tech and throwing people at the problem,” he said. “This caught our attention — we spent months talking to and building for enterprise users at warehouses, factories, freight yards and ports and eventually, in 2018, decided to start Pando to solve for global logistics through a software-as-a-service platform offering.”', metadata={'source': 'data_input/new_articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt'}),\n",
       " Document(page_content='Pando also taps algorithms and forms of machine learning to make predictions around supply chain events. For example, the platform attempts to match customer orders with suppliers, customers through the “right” channel (in terms of aspects like cost and carbon footprint) and fulfillment strategy (e.g. mode of freight, carrier, etc.). Beyond this, Pando can detect anomalies among deliveries, orders and freight invoices and anticipate supply chain risk given demand and supply trends.\\n\\nPando isn’t the only vendor doing this. Altana, which bagged $100 million in venture capital last October, uses an AI system to connect to and learn from logistics and business-to-business data — creating a shared view of supply chain networks. Everstream, another Pando rival, offers its own dashboards for data analysis, integrated with existing ERP, transportation management and supplier relationship management systems.', metadata={'source': 'data_input/new_articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt'}),\n",
       " Document(page_content='Customers can customize the tools and apps or build their own using Pando’s APIs. This, along with the platform’s emphasis on no-code capabilities, differentiates Pando from incumbents like SAP, Oracle, Blue Yonder and E2Open, Jayakrishnan asserts.\\n\\n“Pando comes pre-integrated with leading enterprise resource planning (ERPs) systems and has ready APIs and a professional services team to integrate with any new ERPs and enterprise systems,” he added. “Pando’s no-code capabilities enable business users to customize the apps while maintaining platform integrity — reducing the need for IT resources for each customization.”', metadata={'source': 'data_input/new_articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt'}),\n",
       " Document(page_content='Signaling that investments in the supply chain sector remain robust, Pando, a startup developing fulfillment management technologies, today announced that it raised $30 million in a Series B round, bringing its total raised to $45 million.\\n\\nIron Pillar and Uncorrelated Ventures led the round, with participation from existing investors Nexus Venture Partners, Chiratae Ventures and Next47. CEO and founder Nitin Jayakrishnan says that the new capital will be put toward expanding Pando’s global sales, marketing and delivery capabilities.\\n\\n“We will not expand into new industries or adjacent product areas,” he told TechCrunch in an email interview. “Great talent is the foundation of the business — we will continue to augment our teams at all levels of the organization. Pando is also open to exploring strategic partnerships and acquisitions with this round of funding.”', metadata={'source': 'data_input/new_articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt'})]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process allows us to search for the documents that are semantically similar to the query question within the loaded vector database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q&A System Implementation\n",
    "\n",
    "After identifying the similar documents from the query, we can now advance the implementation by creating a Question-Answering (Q&A) system. This system will utilize the relevant information retrieved from the vector database to provide answers to specific questions asked by the users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All we need to do is import the library `dotenv` to load the environment variables, `load_qa_chain` to set up the Question-Answering chain, and the specific model we want to use from HuggingFaceHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain import HuggingFaceHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load HuggingFace token from env\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the LLM\n",
    "llm = HuggingFaceHub(repo_id=\"declare-lab/flan-alpaca-large\",\n",
    "                     model_kwargs={\"temperature\":0.9, \"max_length\":512})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading the LLM model \"declare-lab/flan-alpaca-large\" from Hugging Face, we can create a Question-Answering (QA) chain using the `load_qa_chain` function provided by LangChain. This QA chain allows us to interact with the model and generate responses to questions based on the input provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create qa chain\n",
    "qa_chain = load_qa_chain(llm, chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using `chain_type=\"stuff\"`, the method allows us to build a QA chain that uses retrieval-based question answering. \n",
    "\n",
    "> In this approach, the model first retrieves relevant documents or passages from a database (in this case, the Chroma vector database) based on the input question. Then, the model generates the answer from the retrieved information. This method is useful for efficiently obtaining contextually relevant answers from a large corpus of data without relying solely on pre-defined answers in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the Results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `.run`, we can execute the Q&A system and provide the input document and the question as parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate answer from related document (from similarity search result)\n",
    "response = qa_chain.run(input_documents=similar_docs, question=question)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chaining\n",
    "\n",
    "**Retriever**\n",
    "\n",
    "In order to retrieve the relevant data from the database, we need to create a retriever. This retriever will return all the documents (or chunks) related to the question asked using `as_retriever()`. It will utilize the data stored in the database (vector database) to identify the most relevant documents that match the user's question, allowing the Q&A system to extract the necessary information efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create retriever\n",
    "retriever = vectordb_load.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RetrievalQA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating the retriever, we can implement the question-answering functionality using `RetrievalQA`. This allows us to match the user's question with the relevant documents retrieved by the retriever and generate contextually relevant answers based on the information stored in the vector database. `RetrievalQA` integrates the retrieved documents with the language model, enabling the system to provide accurate responses to the user's queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# create the chain to answer questions\n",
    "# so we can cut the process/code to generate answer from related document\n",
    "qa_chain = RetrievalQA.from_chain_type(llm = llm,\n",
    "                                  chain_type = \"stuff\",\n",
    "                                  retriever = retriever,\n",
    "                                  return_source_documents = True,\n",
    "                                  verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain(\"what is Pando Vision?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe the same results as our previously built QnA system, but with a more straightforward and streamlined process due to **\"chaining\"** the various components using LangChain's Chain feature. This chaining functionality simplifies the implementation and improves the overall efficiency of the system, making it a powerful tool for creating question-answering applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create QnA System From PDF Source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After successfully creating the QnA System from the Vector Database using Chroma, in this section, we will move on to the next step, which is creating a QnA System from a PDF source. \n",
    "\n",
    "This new approach will demonstrate how to handle text data in PDF format and utilize **LangChain** to build a QnA system that can answer questions based on the content of the **PDF documents**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Problem\n",
    "\n",
    "In important meetings, documentation is often required to record crucial information. However, we may not need to access all the information, but only specific details that are essential. These confidential documents can be used as data to be embedded and create a Q&A system, enabling us to quickly retrieve relevant information and answer specific questions without having to go through the entire document manually. This Q&A system will enhance efficiency and accessibility to the essential data from the secret documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "In this example, we will use the [**\"Copy of minutes of meeting\" document from the Australian Securities & Investments Commission**](https://www2.deloitte.com/content/dam/Deloitte/au/Documents/finance/insolvency/virgin/deloitte-au-fa-virgin-australia-minutes-to-6th-coI-meeting-10-august-2020-010920.pdf) in PDF format. This data contains important details about the minutes of a meeting. To facilitate embedding, we can effortlessly load the PDF data using the `UnstructuredPDFLoader` provided by Langchain. This loader allows us to process unstructured data, such as PDF files, and prepare them for embedding in the Q&A system. By using this method, we can efficiently access and analyze essential information from the PDF documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredPDFLoader \n",
    "\n",
    "def loadPDFFromLocal(pdf_file_path=\"data_input/Eurovision_Song_Contest_2023.pdf\"):\n",
    "    loader = UnstructuredPDFLoader(pdf_file_path)\n",
    "    loaded_docs = loader.load()\n",
    "    return loaded_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading the PDF file using `UnstructuredPDFLoader`, we need to further process the document by splitting it into smaller sections **to improve efficiency in handling large amounts of text**. \n",
    "\n",
    "To achieve this, we can utilize the `CharacterTextSplitter`. This step allows us to create smaller chunks or paragraphs from the original document, making it easier to manage and extract relevant information for embedding and the Q&A system. By using the `CharacterTextSplitter`, we can efficiently process lengthy documents and prepare them for the embedding process and subsequent question-answering tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "# Example of minutes of meeting\n",
    "document = loadPDFFromLocal(\"data_input/deloitte-au-fa-virgin-australia-minutes.pdf\")\n",
    "# split it into chunks\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=10)\n",
    "text = text_splitter.split_documents(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding and Vector Database Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before creating the Q&A system, we can leverage Chroma to process our text data and generate embeddings. To achieve this, we need to utilize the `Chroma.from_documents` method. During this process, we have to specify three essential parameters:\n",
    "\n",
    "1. **Text data:** We need to provide the text data that we want to embed. This could be a single document or multiple documents.\n",
    "\n",
    "2. **Embedding function:** We should define an embedding function, such as `SentenceTransformerEmbeddings`, which will transform the text into meaningful embeddings.\n",
    "\n",
    "3. **Persist directory:** This parameter specifies the directory where the Chroma database, along with the embedded vectors, will be saved. By setting the `persist_directory`, we can efficiently store and reuse the already computed embeddings, saving time and resources in subsequent queries and tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the open-source embedding function\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# save it into Chroma\n",
    "vectordb_pdf = Chroma.from_documents(text, embedding_function, persist_directory=\"./chroma_db_pdf\")\n",
    "vectordb_pdf.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After saving the Chroma database to the disk with the `persist_directory=\"./chroma_db_pdf\"`, we have the option to reload and access the saved data later using the Chroma function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if want to load again from disk\n",
    "vectordb_pdf = Chroma(persist_directory=\"./chroma_db_pdf\", embedding_function=embedding_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By loading the database from the disk, we can efficiently reuse the previously computed embeddings, which can be crucial when dealing with large amounts of text data. This capability allows us to access the saved embeddings whenever needed, without the need to recompute them, thereby **improving the efficiency and speed of text processing** tasks like question-answering systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q&A System Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement the Q&A system, the workflow involves creating a **retriever**, which helps to retrieve relevant documents or chunks based on the given questions. Then, we proceed to **create the chain**, which uses the retriever's output to answer the questions. \n",
    "\n",
    "By doing so, we can **streamline the process and simplify the code** required to generate answers from related documents, making the Q&A system efficient and effective in handling various queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create retriever\n",
    "retriever = vectordb_pdf.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The retriever is responsible for finding relevant documents or chunks in the vector database based on the given input question. It returns the search results that can be used to generate an answer to the question. The retriever plays a crucial role in efficiently retrieving important information from the vector database, which is then used by the Q&A system to provide accurate answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# create the chain to answer questions\n",
    "# so we can cut the process/code to generate answer from related document\n",
    "qa_chain_pdf = RetrievalQA.from_chain_type(llm = llm,\n",
    "                                  chain_type = \"stuff\",\n",
    "                                  retriever = retriever,\n",
    "                                  return_source_documents = True,\n",
    "                                  verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the Results\n",
    "\n",
    "We have reached the end of building the Q&A system, and now we can display the results by inputting the questions to the system. The system will then process the questions and provide relevant answers based on the retrieved information from the vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain_pdf(\"Who is the chairperson of the meeting?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain_pdf(\"Who is the chairperson of the meeting?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = qa_chain_pdf(\"What is the agenda of the meeting?\")\n",
    "\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain_pdf(\"What is the resolution of the meeting?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain_pdf(\"What's the action plan of to fix or determine the remuneration of the administrators?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dive Deeper\n",
    "\n",
    "We've covered the entire workflow, starting from implementing embedding to creating a Q&A system that assists us in finding relevant information. Next, we'll introduce another dataset that you can use to practice and deepen your understanding of the workflow.\n",
    "\n",
    "This document contains information about [\"KINERJA DAN PROSPEK EKONOMI NASIONAL: OPTIMIS DAN WASPADA\"](https://www.bi.go.id/id/publikasi/laporan/Documents/4_LPI2022_BAB2.pdf) from Bank Indonesia. Your task is to create a Q&A system that can answer questions based on the information provided in the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "In this module, we have learned about the workflow to create a Q&A system using unstructured data. By understanding embedding, we can process and represent text data in a meaningful way. We also explored Chroma, which allows us to efficiently store and retrieve embedded data. With these tools, we can build powerful Q&A systems that can answer questions based on the information in unstructured documents."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_dev",
   "language": "python",
   "name": "llm_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "238.932px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
