{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b304a6c",
   "metadata": {},
   "source": [
    "**Coursebook: Introduction to Large Language Models**\n",
    "\n",
    "- Part 1 of Large Language Models Specialization\n",
    "- Course Length: 9 hours\n",
    "- Last Updated: July 2023\n",
    "\n",
    "---\n",
    "\n",
    "Developed by Algoritma's Research and Development division"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cec18d",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "The coursebook is part of the **Large Language Models Specialization** developed by [Algoritma](https://algorit.ma/). The coursebook is intended for a restricted audience only, i.e. the individuals and organizations having received this coursebook directly from the training organization. It may not be reproduced, distributed, translated or adapted in any form outside these individuals and organizations without permission.Algoritma is a data science education center based in Jakarta. We organize workshops and training programs to help working professionals and students gain mastery in various data science sub-fields: data visualization, machine learning, data modeling, statistical inference etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a912e791",
   "metadata": {},
   "source": [
    "# Introduction to Large Language Models\n",
    "\n",
    "## Training Objective\n",
    "\n",
    "Generative AI has revolutionized various industries, offering innovative solutions and driving advancements in natural language understanding. Throughout this module, we will delve into the concept of LLM, its applications in diverse business industries, and the ethical considerations associated with its use. We will witness the real-world impact of LLM through engaging demonstrations in different business contexts. Additionally, we will set up the development environment, with Python as the primary programming language, to equip you with the necessary skills for this training. Before diving into the core discussions, we will lay the groundwork by covering Python basics for language preprocessing, introducing the fundamentals of natural language processing, and exploring essential text libraries.\n",
    "\n",
    "- **Introduction to Generative AI**\n",
    "   - Overview of Generative AI and its real-world applications\n",
    "   - Introduction to the concept of Large Language Models (LLM)\n",
    "   - Demonstration of LLM usage in various business contexts\n",
    "   - Setting up the development environment\n",
    "\n",
    "- **Introduction to Python for Language Preprocessing**\n",
    "   - Python basics for beginners\n",
    "   - Variables, data types, basic operations, and functions in Python\n",
    "   - Control structures: Conditional statements and loops\n",
    "\n",
    "- **Basics of Language Processing**\n",
    "   - Introduction to Natural Language Processing (NLP)\n",
    "   - Exploring word embeddings and their role in language models\n",
    "   - Introduction to major text libraries in Python (e.g., NLTK, spaCy)\n",
    "   - Understanding text preprocessing and tokenization\n",
    "   - Demonstration of library usage for simple text tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad57b81",
   "metadata": {},
   "source": [
    "## Introduction to Generative AI\n",
    "\n",
    "**Generative AI**\n",
    "\n",
    "Generative AI refers to a branch of artificial intelligence that focuses on creating or generating new content that resembles human-created output. It uses advanced machine learning techniques to learn patterns and characteristics from existing data and then generate new data based on that learned knowledge. In simpler terms, generative AI models are designed to mimic human creativity and generate new content that can include **images, text, music, and even video**.\n",
    "\n",
    "To generate new content, generative AI models utilize a variety of techniques such as deep learning, neural networks, and probabilistic models. These models learn from examples and can generate new content by sampling from the learned patterns and creating new combinations or variations.\n",
    "\n",
    "<img src=\"https://algorit.ma/wp-content/uploads/2020/08/Screen_Shot_2020-08-10_at_9.02.50_PM.png\" width=\"300\">\n",
    "\n",
    "#### Artificial Intelligence (AI) \n",
    "\n",
    "Artificial Intelligence (AI) is a broad field that encompasses the development of intelligent systems capable of performing tasks that typically require human intelligence. AI can be further divided into subfields such as machine learning and deep learning, which are integral to generative AI.\n",
    "\n",
    "#### Machine Learning (ML)\n",
    "\n",
    "Machine Learning (ML) is a subset of AI that focuses on developing algorithms and models that allow computers to learn patterns and make predictions or decisions without being explicitly programmed. ML algorithms learn from training data, iteratively improving their performance through experience.\n",
    "\n",
    "In the context of generative AI, machine learning plays a crucial role in **training models to generate new content**. These models learn from existing data to capture patterns, structures, and features that define the content. By leveraging machine learning algorithms, generative AI models can generate new content that resembles the training data.\n",
    "\n",
    "#### Deep Learning \n",
    "\n",
    "Deep Learning is a specialized branch of machine learning that is inspired by the structure and function of the human brain. Deep learning models, known as artificial neural networks, are designed to learn hierarchical representations of data through multiple layers of interconnected nodes, called neurons. Each layer of neurons learns increasingly complex and abstract features from the data.\n",
    "\n",
    "Deep learning has significantly advanced generative AI by **enabling the development of complex and sophisticated models capable of generating high-quality content**. Deep learning models, such as generative adversarial networks (GANs) and recurrent neural networks (RNNs), have shown remarkable abilities in generating realistic images, coherent text, and even human-like speech.\n",
    "\n",
    "\n",
    "**Generative AI Real-world Applications**\n",
    "\n",
    "The real-world applications of generative AI are vast and diverse, spanning various industries and domains. One notable application is in the field of creative content generation. Generative models have been used to create artwork, music, and literature, sometimes indistinguishable from those produced by human artists. These models can unleash unprecedented levels of creativity and provide new avenues for artistic expression.\n",
    "\n",
    "- In the realm of **healthcare**, generative AI has shown immense potential. It has been employed to generate synthetic medical images and aid in medical diagnosis. By training generative models on vast amounts of medical data, these models can generate realistic images of organs, tumors, or anomalies, assisting healthcare professionals in accurate diagnosis and treatment planning.\n",
    "\n",
    "- Generative AI also plays a vital role in the field of natural language processing and **text generation**. Language models, powered by generative AI, can generate coherent and contextually relevant text. This technology finds applications in chatbots, virtual assistants, and language translation services, enabling more natural and human-like interactions with machines.\n",
    "\n",
    "- Another area where generative AI shines is in the domain of **data augmentation**. By synthesizing new data samples, generative models can expand and enhance limited datasets, aiding in training machine learning models. This augmentation technique can help improve the robustness and performance of models in various domains, including image classification, speech recognition, and sentiment analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b88417",
   "metadata": {},
   "source": [
    "## Introduction to Large Language Models (LLM)\n",
    "\n",
    "Generative AI, on the other hand, encompasses a broader range of models and techniques that aim to generate new content across different domains, including images, music, and text. It focuses on creating output that resembles human-created content.\n",
    "\n",
    "LLMs are a specific application of generative AI that is tailored to text generation. They use generative AI techniques, such as probabilistic modeling and sequence prediction, to generate human-like text. By modeling the statistical properties of language, LLMs can generate text that is coherent, relevant, and often indistinguishable from human-written text.\n",
    "\n",
    "The term \"large\" in the context of Large Language Models (LLMs) refers to two aspects:\n",
    "\n",
    "**1. Large training dataset**\n",
    "\n",
    " - LLMs are typically trained on massive amounts of text data to capture the statistical patterns and structures present in the language.\n",
    " - The training dataset can consist of diverse sources such as books, articles, websites, and other text corpora, providing a wide range of linguistic patterns and contexts.\n",
    " - By using a large training dataset, LLMs have the opportunity to learn from a vast amount of information and improve their language modeling capabilities.\n",
    "    \n",
    "**2. Large Number of parameters**\n",
    "\n",
    " - LLMs are characterized by a significant number of parameters, which are learnable variables that determine the behavior of the model.\n",
    " - The number of parameters in LLMs can range from millions to billions, depending on the size and complexity of the model.\n",
    " - Increasing the number of parameters allows LLMs to capture more intricate language patterns and generate more coherent and contextually relevant text.\n",
    " - Models with a larger number of parameters can handle a broader range of language tasks and exhibit enhanced language generation capabilities.\n",
    " \n",
    "#### LLM are trained to solve commong languge problem\n",
    "\n",
    "Large Language Models (LLMs) are trained to solve common text-related tasks such as:\n",
    "\n",
    "<img title=\"a title\" src=\"assets/llm_problem.png\">\n",
    "\n",
    "1. Text Classification:\n",
    "   - LLMs can be fine-tuned to perform text classification tasks, where they classify text into predefined categories or labels. By training on labeled examples, LLMs learn to recognize patterns and features in text that are indicative of specific categories or classes.\n",
    "   - For example, LLMs can be trained to classify emails as spam or non-spam, sentiment analysis to determine the sentiment of a text (positive, negative, or neutral), or topic classification to categorize news articles into different topics.\n",
    "\n",
    "\n",
    "2. Question Answering:\n",
    "   - LLMs are capable of understanding and generating answers to questions based on a given context or knowledge base. By training on question-answer pairs or by utilizing techniques such as prompting, LLMs learn to comprehend the question and generate relevant and accurate answers.\n",
    "   - They can be employed in chatbots, virtual assistants, or search engines to provide responses to user queries.\n",
    "\n",
    "\n",
    "3. Document Summarization:\n",
    "   - LLMs can be utilized for document summarization, where they generate concise summaries of long documents. By training on pairs of long documents and their corresponding summaries, LLMs learn to identify important information and generate coherent summaries.\n",
    "   - Document summarization with LLMs can aid in information retrieval, content analysis, and data compression.\n",
    "\n",
    "\n",
    "4. Text Generation:\n",
    "   - LLMs are proficient in generating human-like text, making them useful for text generation tasks. LLMs utilize their language understanding and generation capabilities to produce coherent and contextually appropriate text outputs.\n",
    "   - They can be fine-tuned to generate creative stories, poetry, product descriptions, and more.\n",
    "\n",
    "\n",
    "#### General Purpose\n",
    "\n",
    "The general purpose of Large Language Models (LLMs) is to understand, generate, and process human language. LLMs aim to capture the commonalities and patterns across different human languages and provide a versatile framework for a wide range of natural language processing tasks. Two key aspects related to the purpose of LLMs are the commonality of human languages and resource restrictions.\n",
    "\n",
    "**1. Commonality of human**\n",
    "\n",
    "- LLMs are designed to capture the underlying structures and patterns that are common across various human languages.\n",
    "- By training on diverse multilingual datasets, LLMs learn to generalize linguistic patterns, syntax, semantics, and contextual information that are shared among different languages.\n",
    "- This enables LLMs to perform language-related tasks such as machine translation, sentiment analysis, text summarization, and question answering in multiple languages.\n",
    "- LLMs can leverage the learned representations to transfer knowledge and adapt to new languages or domains, making them versatile tools for multilingual natural language processing.\n",
    "\n",
    "**2. Resource restriction**\n",
    "\n",
    "- LLMs also address the issue of resource restrictions in language-related tasks.\n",
    "- Traditional language processing approaches often rely on handcrafted linguistic rules or domain-specific knowledge bases, which require significant human effort and expertise.\n",
    "- LLMs, on the other hand, have the potential to learn from large amounts of unlabeled text data, reducing the need for extensive manual annotation or rule-based systems.\n",
    "- By training on massive datasets, LLMs acquire a comprehensive understanding of language, enabling them to generate coherent and contextually relevant text across different domains and topics.\n",
    "- This makes LLMs valuable resources in situations where access to domain-specific labeled data or expertise is limited.\n",
    "\n",
    "\n",
    "#### Benefit of using large language models\n",
    "\n",
    "1. **A single model can be used for different tasks**: With a single LLM model, it becomes possible to tackle different language-related tasks, reducing the need for task-specific models and simplifying the development process.\n",
    "2. **The fine-tune process requires minimal field data**: Unlike training models from scratch, fine-tuning requires fewer labeled examples, saving time and resources in data annotation and model training.\n",
    "3. **The performance is continously growing with more data and parameters**: With ongoing advancements in computational resources and access to larger datasets, LLMs have the potential to achieve even better performance in the future.\n",
    "\n",
    "\n",
    "#### LLM Development vs. Traditional Development\n",
    "\n",
    "| LLM Development (using pre-trained API)     | Traditional ML Development |\n",
    "| ----------- | ----------- |\n",
    "| NO ML expertise needed      | YES ML expertise needed       |\n",
    "| NO training examples   | YES training examples        |\n",
    "| NO need to train a model | YES need to train a model|\n",
    "| Thinks about prompt design | Thinks about minimizing a loss function|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c5020a",
   "metadata": {},
   "source": [
    "## LLM usage in various business contexts\n",
    "\n",
    "Demonstrating the usage of Large Language Models (LLMs) in various business contexts involves showcasing their capabilities and applications in real-world scenarios. Here are some examples of how LLMs can be demonstrated in different business contexts:\n",
    "\n",
    "**1. Customer Support and Chatbots:**\n",
    "   - Showcasing a chatbot powered by an LLM that can handle customer inquiries, provide product recommendations, and assist with common support issues.\n",
    "   - Demonstrating the chatbot's ability to understand and respond to user queries, maintaining a natural and conversational interaction.\n",
    "\n",
    "**2. Content Generation and Marketing:**\n",
    "   - Demonstrating how an LLM can generate engaging and personalized content for marketing campaigns, social media posts, or email newsletters.\n",
    "   - Showcasing the LLM's ability to generate content that aligns with the brand's voice and resonates with the target audience.\n",
    "\n",
    "**3. Data Analysis and Insights:**\n",
    "   - Demonstrating how an LLM can analyze large volumes of customer feedback, reviews, or survey responses to extract valuable insights.\n",
    "   - Showcasing the LLM's ability to identify trends, sentiments, and key topics within the data, enabling data-driven decision-making.\n",
    "\n",
    "**4. Document Processing and Automation:**\n",
    "   - Demonstrating how an LLM can automate the processing of documents, such as contract analysis, by extracting relevant information, identifying clauses, or generating summaries.\n",
    "   - Showcasing the time-saving and accuracy improvements achieved through LLM-powered document automation.\n",
    "\n",
    "**5. Language Translation and Localization:**\n",
    "   - Demonstrating an LLM's ability to perform accurate language translation across multiple languages.\n",
    "   - Showcasing how the LLM can handle nuances, idioms, and context-specific translations, enabling effective communication in global markets.\n",
    "\n",
    "**6. Data-driven Decision-making:**\n",
    "   - Demonstrating how an LLM can analyze market trends, customer behavior, or social media data to provide insights for strategic decision-making.\n",
    "   - Showcasing the LLM's ability to identify patterns, correlations, or emerging topics within the data, facilitating informed business decisions.\n",
    "\n",
    "These demonstrations provide concrete examples of how LLMs can be applied in various business contexts, showcasing their capabilities and potential benefits. They help stakeholders understand the practical applications of LLMs and how they can be leveraged to enhance business processes, improve customer experiences, and drive innovation in different industries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03c9fa3",
   "metadata": {},
   "source": [
    "## Setting up the development environment\n",
    "\n",
    "Python is a versatile and widely adopted programming language that is exceptionally well-suited for working with Large Language Models (LLMs). Its simplicity, readability, and extensive ecosystem of libraries and tools make it an ideal choice for developing and leveraging the capabilities of LLMs. Python offers a rich set of libraries specifically designed for natural language processing (NLP) tasks, such as Hugging Face's Transformers, OpenAI API, NLTK, spaCy, and TensorFlow. These libraries provide convenient functionality for tasks like preprocessing, fine-tuning, and text generation, simplifying the implementation process. \n",
    "\n",
    "Setting up the development environment for using Large Language Models (LLMs) with Python involves the necessary steps to configure your system to effectively work with LLMs. Here is an explanation of the general process:\n",
    "\n",
    "**1. Install Anaconda**: Begin by downloading and installing Anaconda, a popular Python distribution that includes the Anaconda Navigator and conda package manager. Visit the Anaconda website (https://www.anaconda.com) and follow the instructions for your operating system.\n",
    "\n",
    "**2. Open Anaconda Prompt** (Windows) or Terminal (macOS/Linux): Launch the Anaconda Prompt or Terminal, which provides a command-line interface for executing Anaconda-related commands.\n",
    "\n",
    "**3. Create a Virtual Environment**: In the Anaconda Prompt or Terminal, use the following command to create a new virtual environment named `llm-env` (you can replace `llm-env` with your desired environment name):\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "  <code>conda create --name llm-env python=3.10</code>\n",
    "</div> \n",
    "\n",
    "**4. Activate the Environment:** Activate the Virtual Environment: Once the virtual environment is created, activate it using the following command:\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "  <code>conda activate llm-env</code>\n",
    "</div> \n",
    "\n",
    "**5. Install Dependencies** from `requirements.txt`: If you have a `requirements.txt` file that contains a list of dependencies, you can install them into your virtual environment using the following command:\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "  <code>pip install -r requirements.txt\n",
    "</code>\n",
    "</div> \n",
    "Make sure the `requirements.txt` file is present in the directory where you are executing the command. This command will install all the dependencies specified in the file.\n",
    "\n",
    "**6. Launch Jupyter Notebook**: After installing the dependencies, you can launch Jupyter Notebook by executing the following command in the Anaconda Prompt or Terminal: \n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "  <code>jupyter notebook\n",
    "</code>\n",
    "</div> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111b4e97",
   "metadata": {},
   "source": [
    "## Introduction to Python for Language Preprocessing\n",
    "\n",
    "Python is a powerful programming language that offers a wide range of tools and libraries for language preprocessing tasks in the field of natural language processing (NLP). This section provides an overview of Python's essential concepts and features relevant to language preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0fc49d",
   "metadata": {},
   "source": [
    "### Basic Python Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ad38d3",
   "metadata": {},
   "source": [
    "#### Variables and Keywords\n",
    "\n",
    "In Python, variables are used to store data values. They serve as containers for holding values that can be referenced and manipulated throughout the program.\n",
    "\n",
    "- **Variable Declaration**: To declare a variable in Python, you simply assign a value to it using the assignment operator `(=)`. The variable name should be meaningful and follow certain naming conventions (e.g., start with a letter or underscore, avoid using reserved keywords)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bcd31cce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T10:28:25.658094Z",
     "start_time": "2023-07-07T10:28:25.654649Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "programming\n"
     ]
    }
   ],
   "source": [
    "activity = 'programming'\n",
    "\n",
    "print(activity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb5338f",
   "metadata": {},
   "source": [
    " Thing to note here, like other programming languages, Python is **case-sensitive**, so `activity` and `Activity` are  different symbols and will point to different variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "37083638",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T10:28:25.665404Z",
     "start_time": "2023-07-07T10:28:25.660889Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'activity' == 'Activity'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "321cfda3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T10:28:25.672421Z",
     "start_time": "2023-07-07T10:28:25.668143Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " activity == activity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27c1f63",
   "metadata": {},
   "source": [
    "Our previous code returned `True` as the output. Try to create a new variable and use `True` as the variable name, then see what happen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b12e4ea",
   "metadata": {},
   "source": [
    "**Keywords** in Python are reserved words that have specific meanings and purposes within the language. These keywords **cannot be used** as variable names because they are already used by Python to perform specific tasks or operations.\n",
    "Examples of keywords: `if`, `else`, `for`, `while`, `def`, `import`, `return`, `class`, `True`, `False`, `None`, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641c3ca8",
   "metadata": {},
   "source": [
    "#### Python Data Types\n",
    "\n",
    "In Python, data types represent the kind of values that variables can hold. Each data type has its own characteristics and behavior. Here's an explanation of some commonly used data types in Python along with examples:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20eab3ac",
   "metadata": {},
   "source": [
    "**1. Numeric Types:**\n",
    "\n",
    "To store numbers, python has two native data types called `int` and `float`.\n",
    "\n",
    "- `int` is used to store integers (ie: 1,2,-3)\n",
    "- `float` is used to store real numbers (ie: 0.7, -1.8, -1000.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b3f7b64d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T10:28:25.678508Z",
     "start_time": "2023-07-07T10:28:25.674391Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# int\n",
    "age = 25\n",
    "type(age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "40d596e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T10:28:25.686226Z",
     "start_time": "2023-07-07T10:28:25.681774Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# float\n",
    "weight = 68.5\n",
    "type(weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f845cc5",
   "metadata": {},
   "source": [
    "**Numeric Operations** \n",
    "\n",
    "Arithmetic Operators:\n",
    "\n",
    "- `+` - Addition\n",
    "- `-` - Subtraction\n",
    "- `*` - Multiplication\n",
    "- `/` - Division\n",
    "- `//` - Round division\n",
    "- `%` - Module\n",
    "- `**` - Exponent\n",
    "\n",
    "Comparison Operators:\n",
    "\n",
    "- `<` - Less than (ie : a < b)\n",
    "- `<=` - Less than or equal to (ie : a <= b)\n",
    "- `>` - Greater than (ie: a > b)\n",
    "- `>=` - Greater than or equal to (ie: a >= b)\n",
    "- `==` - Equals (ie: a == b)\n",
    "- `!=` - Not Equal (ie: a != b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4025181",
   "metadata": {},
   "source": [
    "**2. Strings**\n",
    "\n",
    "Strings are used in Python to record text information, such as names. Strings in Python are actually a sequence, which basically means Python keeps track of every element in the string as a sequence. For example, Python understands the string \"hello' to be a sequence of letters in a specific order. This means we will be able to use indexing to grab particular letters (like the first letter, or the last letter).\n",
    "\n",
    "Python represents any string as a `str` object. There are several ways to create a string value:\n",
    "\n",
    "- using `''` (ie: `'cyber punk 2077'``)\n",
    "- using `\"\"` (ie : `\"Hari Jum'at\"`)\n",
    "- using `'''` or `\"\"\"` (ie: `'''Andi berkata \"Jum'at Bersih\"'''`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1a22c07b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T10:28:25.693000Z",
     "start_time": "2023-07-07T10:28:25.688277Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# str\n",
    "school = \"Algoritma\"\n",
    "type(school)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192a07ba",
   "metadata": {},
   "source": [
    "**3. Boolean**\n",
    "\n",
    "Boolean stores a very simple value in computers and programming, `True` or `False`.\n",
    "\n",
    "**Boolean operations**\n",
    "\n",
    "Python provides logical operators such as:\n",
    "\n",
    "- and (ie: a and b)\n",
    "- or (ie: a or c)\n",
    "- not (ie: not a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b5a83858",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T10:28:25.699848Z",
     "start_time": "2023-07-07T10:28:25.695552Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bool"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# boolean\n",
    "is_student = True\n",
    "type(is_student)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cb3901",
   "metadata": {},
   "source": [
    "#### Python Data Structures\n",
    "\n",
    "Python provides several built-in data structures that allow you to organize and store collections of data. These data structures are essential for efficient data manipulation and are widely used in Python programming. Here's an explanation of some commonly used data structures along with examples:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54f30ec",
   "metadata": {},
   "source": [
    "**1. List**\n",
    "\n",
    "Lists are ordered collections of items enclosed in square brackets (`[]`). They can store elements of different data types and allow duplicate values. Lists support indexing and slicing, which enable you to access and manipulate specific elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "408d766f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T10:28:25.705389Z",
     "start_time": "2023-07-07T10:28:25.701893Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple\n"
     ]
    }
   ],
   "source": [
    "fruits = [\"apple\", \"banana\", \"orange\"]\n",
    "print(fruits[0])  # Output: \"apple\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d70298",
   "metadata": {},
   "source": [
    "**Operation List**\n",
    "\n",
    "- `x.append(a)` : add a to x\n",
    "- `x.remove(a)` : remove a from x\n",
    "\n",
    "In addition to the previously known operators, one of the most useful lists is to implement an aggregation function such as:\n",
    "\n",
    "- `len(x)` : extract the length of the list\n",
    "- `a in b` : checks if the value `a` exists in the list object `b`\n",
    "- `max(x)` : get the highest value in x\n",
    "- `sum(x)` : get the number of values in x\n",
    "\n",
    "Another operation to be aware of in lists is indexing:\n",
    "\n",
    "- `x[i]` : access the i-th element of x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff983c7",
   "metadata": {},
   "source": [
    "**2. Tuples**\n",
    "\n",
    "Tuples are similar to lists but are immutable, meaning their values cannot be changed after creation. They are defined using parentheses `()` and are typically used for grouping related values. Tuples are often used when you want to ensure data integrity or prevent accidental modifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "30223efe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T10:28:25.711102Z",
     "start_time": "2023-07-07T10:28:25.707661Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 5\n"
     ]
    }
   ],
   "source": [
    "point = (3, 5)\n",
    "x, y = point\n",
    "print(x, y)  # Output: 3, 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c6fb4d",
   "metadata": {},
   "source": [
    "**3. Sets**\n",
    "\n",
    "Sets are unordered collections of unique elements enclosed in curly braces (`{}`) or created using the `set()` function. They do not support indexing, and the order of elements may vary. Sets are useful for performing mathematical set operations like union, intersection, and difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "462820c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T10:28:25.720153Z",
     "start_time": "2023-07-07T10:28:25.716520Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1, 2, 3, 4, 5, 6}\n"
     ]
    }
   ],
   "source": [
    "numbers = {1, 2, 3, 4, 5}\n",
    "numbers.add(6)\n",
    "print(numbers)  # Output: {1, 2, 3, 4, 5, 6}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037ea2e4",
   "metadata": {},
   "source": [
    "**4. Dictionaries**\n",
    "\n",
    "Dictionaries store data in key-value pairs enclosed in curly braces (`{}`). Each element in a dictionary consists of a unique key and its corresponding value. Dictionaries provide fast lookup operations based on keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "43a3bd1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T10:28:25.725001Z",
     "start_time": "2023-07-07T10:28:25.722042Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make a dictionary with {} and : to signify a key and a value\n",
    "my_dict = {'key1':'value1',\n",
    "           'key2':'value2'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b96bc8e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T10:28:25.731131Z",
     "start_time": "2023-07-07T10:28:25.727049Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'value2'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call values by their key\n",
    "my_dict['key2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b66a1ca",
   "metadata": {},
   "source": [
    "Some common operations and methods for dictionaries in Python:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b981309",
   "metadata": {},
   "source": [
    "- Accessing Values: Dictionaries use keys to access corresponding values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0f4d3bb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T10:28:25.736690Z",
     "start_time": "2023-07-07T10:28:25.733357Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John\n"
     ]
    }
   ],
   "source": [
    "student = {\"name\": \"John\", \"age\": 20}\n",
    "print(student[\"name\"])     # Output: \"John\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6ee3dc",
   "metadata": {},
   "source": [
    "- Modifying Values: You can modify the values of a dictionary by assigning a new value to a specific key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "64956b12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T10:28:25.742365Z",
     "start_time": "2023-07-07T10:28:25.739186Z"
    }
   },
   "outputs": [],
   "source": [
    "student = {\"name\": \"John\", \"age\": 20}\n",
    "student[\"age\"] = 21"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7b735f",
   "metadata": {},
   "source": [
    "- Adding and Removing Key-Value Pairs: You can add new key-value pairs to a dictionary using the assignment operator, and remove key-value pairs using the `del` keyword."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c14468cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T10:28:25.747564Z",
     "start_time": "2023-07-07T10:28:25.744592Z"
    }
   },
   "outputs": [],
   "source": [
    "student = {\"name\": \"John\", \"age\": 20}\n",
    "student[\"grade\"] = \"A\"     # Adding a new key-value pair\n",
    "del student[\"age\"]         # Removing a key-value pair"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad1c061",
   "metadata": {},
   "source": [
    "Dictionary Methods: Dictionaries have several useful methods, such as `keys()`, `values()`, and `items()`, which return the keys, values, and key-value pairs, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fe67e240",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T10:28:25.752800Z",
     "start_time": "2023-07-07T10:28:25.749793Z"
    }
   },
   "outputs": [],
   "source": [
    "student = {\"name\": \"John\", \"age\": 20}\n",
    "keys = student.keys()\n",
    "values = student.values()\n",
    "items = student.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d362329",
   "metadata": {},
   "source": [
    "- Checking Key Existence: You can use the `in` keyword to check if a key exists in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2fcb5a4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T10:28:25.758100Z",
     "start_time": "2023-07-07T10:28:25.754966Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age is present in the dictionary\n"
     ]
    }
   ],
   "source": [
    "student = {\"name\": \"John\", \"age\": 20}\n",
    "if \"age\" in student:\n",
    "    print(\"Age is present in the dictionary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55001c9",
   "metadata": {},
   "source": [
    "#### Control structures: Conditional statements and loops\n",
    "\n",
    "Instructions that a Python interpreter can execute are called statements. For example, `a = 1` is an assignment statement. `if` statement, `for` statement, etc.\n",
    "\n",
    "**if and else Statements**\n",
    "\n",
    "`if` Statements in Python allows us to tell the computer to perform alternative actions based on a certain set of results.\n",
    "\n",
    "Verbally, we can imagine we are telling the computer:\n",
    "\n",
    "\"Hey if this case happens, perform some action\"\n",
    "\n",
    "We can then expand the idea further with `elif` and `else` statements, which allow us to tell the computer:\n",
    "\n",
    "\"Hey if this case happens, perform some action. Else, if another case happens, perform some other action. Else, if none of the above cases happened, perform this action.\"\n",
    "\n",
    "Let's go ahead and look at the syntax format for if statements to get a better idea of this:\n",
    "\n",
    "```\n",
    "if case1:\n",
    "    perform action1\n",
    "elif case2:\n",
    "    perform action2\n",
    "else: \n",
    "    perform action3\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3aab7b02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T10:28:25.763254Z",
     "start_time": "2023-07-07T10:28:25.760149Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, it was true\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    print('Yes, it was true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f9490501",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T10:28:25.769228Z",
     "start_time": "2023-07-07T10:28:25.765313Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are in Algoritma\n"
     ]
    }
   ],
   "source": [
    "place = 'Algoritma'\n",
    "if place == 'Algoritma':\n",
    "    print('You are in Algoritma')\n",
    "else:\n",
    "    print('You are not in Algoritma')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e5a3b7",
   "metadata": {},
   "source": [
    "**Notes:** \n",
    "\n",
    "Indentation is important to keep a good understanding of how indentation works in Python to maintain the structure and order of your code. We will touch on this topic again when we start building out functions!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8807bfe3",
   "metadata": {},
   "source": [
    "**for Loops**\n",
    "\n",
    "A `for` loop acts as an *iterator* in Python; it goes through items that are in a sequence or any other iterable item. Objects that we've learned about that we can iterate over include strings, lists, tuples, and even built-in iterables for dictionaries, such as keys or values.\n",
    "\n",
    "We've already seen the `for` statement a little bit in past lectures but now let's formalize our understanding.\n",
    "\n",
    "Here's the general format for a `for` loop in Python:\n",
    "```\n",
    "for item in object:\n",
    "    statements to do stuff\n",
    "```\n",
    "\n",
    "The variable name used for the item is completely up to the coder, so use your best judgment for choosing a name that makes sense and you will be able to understand when revisiting your code. This item name can then be referenced inside your loop, for example if you wanted to use `if` statements to perform checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ac3a47b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T10:28:25.774575Z",
     "start_time": "2023-07-07T10:28:25.771030Z"
    }
   },
   "outputs": [],
   "source": [
    "my_list1 = [1,2,3,4,5,6,7,8,9,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f6d9236c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T10:28:25.779677Z",
     "start_time": "2023-07-07T10:28:25.776714Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "for num in my_list1:\n",
    "    print(num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f386f78",
   "metadata": {},
   "source": [
    "We could have also put an `if` `else` statement in there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e669102a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T10:28:25.786024Z",
     "start_time": "2023-07-07T10:28:25.781912Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Odd number\n",
      "2\n",
      "Odd number\n",
      "4\n",
      "Odd number\n",
      "6\n",
      "Odd number\n",
      "8\n",
      "Odd number\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "for num in my_list1:\n",
    "    if num % 2 == 0:\n",
    "        print(num)\n",
    "    else:\n",
    "        print('Odd number')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f741c22",
   "metadata": {},
   "source": [
    "#### Python Functions\n",
    "\n",
    "A function is a useful device that groups together a set of statements so they can be run more than once. They can also let us specify parameters that can serve as inputs to the functions.\n",
    "\n",
    "On a more fundamental level, functions allow us to not have to repeatedly write the same code again and again. If you remember back to the lessons on strings and lists, remember that we used a function len() to get the length of a string. Since checking the length of a sequence is a common task you would want to write a function that can do this repeatedly at command.\n",
    "\n",
    "**Why even use functions?**\n",
    "\n",
    "Put simply, you should use functions when you plan on using a block of code multiple times. The function will allow you to call the same block of code without having to write it multiple times. This in turn will allow you to create more complex Python scripts. To really understand this though, we should actually write our own functions!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666f6c6a",
   "metadata": {},
   "source": [
    " **Creating a function**\n",
    "\n",
    "\n",
    "In Python a function is defined using the `def` keyword, and follow by function name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f4b63f48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T10:28:25.792591Z",
     "start_time": "2023-07-07T10:28:25.789047Z"
    }
   },
   "outputs": [],
   "source": [
    "def my_function():\n",
    "  print(\"Hello from a function\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0580ff46",
   "metadata": {},
   "source": [
    "**Calling a function**\n",
    "\n",
    "To call a function, use the function name followed by parenthesis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8fe3d3d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T10:28:25.807030Z",
     "start_time": "2023-07-07T10:28:25.802831Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello from a function\n"
     ]
    }
   ],
   "source": [
    "my_function()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1416bf0",
   "metadata": {},
   "source": [
    "**Arguments**\n",
    "\n",
    "\n",
    "Information can be passed into functions as arguments.\n",
    "\n",
    "Arguments are specified after the function name, inside the parentheses. You can add as many arguments as you want, just separate them with a comma.\n",
    "\n",
    "The following example has a function with one argument (`name`). When the function is called, we pass along a first name, which is used inside the function to print the full name:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "34af0ddd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T10:28:25.813420Z",
     "start_time": "2023-07-07T10:28:25.809338Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dwi from Algoritma\n",
      "Irfan from Algoritma\n",
      "Lita from Algoritma\n"
     ]
    }
   ],
   "source": [
    "def my_function(name):\n",
    "  print(name + \" from Algoritma\")\n",
    "\n",
    "my_function('Dwi')\n",
    "my_function('Irfan')\n",
    "my_function('Lita')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83b61d2",
   "metadata": {},
   "source": [
    "**Using return**\n",
    "\n",
    "So far we've only seen `print()` used, but if we actually want to save the resulting variable we need to use the **return** keyword.\n",
    "\n",
    "Let's see some example that use a `return` statement. `return` allows a function to *return* a result that can then be stored as a variable, or used in whatever manner a user wants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a10dc376",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T10:28:25.818516Z",
     "start_time": "2023-07-07T10:28:25.815666Z"
    }
   },
   "outputs": [],
   "source": [
    "def area(width,length):\n",
    "    return width*length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4dd89be3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T10:28:25.825797Z",
     "start_time": "2023-07-07T10:28:25.820941Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "area(4,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e8cb79",
   "metadata": {},
   "source": [
    "**A Very Common Question: \"What is the difference between `return` and `print`?\"**\n",
    "\n",
    "> The `return` keyword allows you to actually save the result of the output of a function as a variable. The `print()` function simply displays the output to you, but doesn't save it for future use. Let's explore this in more detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "87bd4692",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T10:28:25.830626Z",
     "start_time": "2023-07-07T10:28:25.828031Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_result(a,b):\n",
    "    print(a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d5621df9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T10:28:25.836266Z",
     "start_time": "2023-07-07T10:28:25.833152Z"
    }
   },
   "outputs": [],
   "source": [
    "def return_result(a,b):\n",
    "    return a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f7802d58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T10:28:25.842169Z",
     "start_time": "2023-07-07T10:28:25.838456Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "print_result(10,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "cfef6cce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T10:28:25.848643Z",
     "start_time": "2023-07-07T10:28:25.844412Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You won't see any output if you run this in a .py script\n",
    "return_result(10,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e76bfe",
   "metadata": {},
   "source": [
    "But what happens if we actually want to save this result for later use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "340940c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T10:28:25.853659Z",
     "start_time": "2023-07-07T10:28:25.850736Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "my_result = print_result(20,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b54cc40f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T10:28:25.858444Z",
     "start_time": "2023-07-07T10:28:25.855800Z"
    }
   },
   "outputs": [],
   "source": [
    "my_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b27e8413",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T10:28:25.864536Z",
     "start_time": "2023-07-07T10:28:25.860523Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(my_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9b7c3d",
   "metadata": {},
   "source": [
    "> Be careful! Notice how `print_result()` doesn't let you actually save the result to a variable! It only prints it out, with `print()` returning `None` for the assignment!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9abc88a",
   "metadata": {},
   "source": [
    "## Basics of Language Processing\n",
    "\n",
    "Language processing, also known as **natural language processing (NLP)**, is a field of study that focuses on the interaction between computers and human language. It involves the development of algorithms and techniques to enable computers to understand, interpret, and generate human language in a way that is meaningful and useful.\n",
    "\n",
    "The field of language processing encompasses a wide range of tasks, including but not limited to:\n",
    "\n",
    "1. **Tokenization**: Breaking down a text into smaller units, such as words or sentences, known as tokens.\n",
    "\n",
    "2. **Part-of-Speech (POS) Tagging**: Assigning grammatical tags to words in a sentence, indicating their part of speech (e.g., noun, verb, adjective).\n",
    "\n",
    "3. **Named Entity Recognition (NER)**: Identifying and classifying named entities in text, such as person names, locations, organizations, or dates.\n",
    "\n",
    "4. **Sentiment Analysis**: Determining the sentiment or emotional tone expressed in a piece of text, such as positive, negative, or neutral.\n",
    "\n",
    "5. **Text Classification**: Categorizing text into predefined categories or classes based on its content or topic.\n",
    "\n",
    "6. **Language Generation**: Generating human-like text based on given input or prompts.\n",
    "\n",
    "7. **Machine Translation**: Translating text from one language to another.\n",
    "\n",
    "8. **Information Extraction**: Extracting structured information from unstructured text, such as extracting names, dates, or relations from news articles.\n",
    "\n",
    "These are just a few examples of the tasks involved in language processing. Python provides various libraries and tools, such as NLTK (Natural Language Toolkit), spaCy, and scikit-learn, which offer functionalities and pre-trained models to perform these tasks efficiently.\n",
    "\n",
    "By understanding the basics of language processing, you can lay the foundation for more advanced applications, including large language models (LLM), which utilize complex algorithms and deep learning techniques to process and generate human-like language."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbd02a5",
   "metadata": {},
   "source": [
    "### Using `NLTK` dan `spaCy` for simple text processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915d24a5",
   "metadata": {},
   "source": [
    "#### Importing the Required Libraries\n",
    "\n",
    "Begin by importing the necessary libraries for text processing, such as `NLTK` and `spaCy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e136fe80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T10:28:25.869443Z",
     "start_time": "2023-07-07T10:28:25.866666Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e0324d",
   "metadata": {},
   "source": [
    "#### Preprocessing the Text\n",
    "\n",
    "Perform basic text preprocessing tasks, such as tokenization and removing stop words. Tokenization is a crucial step in natural language processing tasks as it breaks down text into smaller units for further analysis, processing, or modeling. Removing stop words helps eliminate noise and focus on more meaningful words when performing text analysis, classification, or other NLP tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1b96eb9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T10:28:25.876355Z",
     "start_time": "2023-07-07T10:28:25.871592Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "text = \"This is a sample sentence.\"\n",
    "tokens = word_tokenize(text)\n",
    "\n",
    "# Removing stop words\n",
    "stop_words = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "filtered_tokens = [token for token in tokens if token.lower() not in stop_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad649262",
   "metadata": {},
   "source": [
    "1. Tokenization:\n",
    "   - The variable `text` contains a sample sentence: \"This is a sample sentence.\"\n",
    "   - The `word_tokenize()` function from NLTK is used to tokenize the sentence into individual words.\n",
    "   - The result is stored in the `tokens` variable, which will contain a list of tokens (words) from the sentence.\n",
    "   \n",
    "\n",
    "2. Removing Stop Words:\n",
    "   - Stop words are common words that do not carry significant meaning in a sentence, such as \"is,\" \"a,\" \"the,\" etc.\n",
    "   - NLTK provides a predefined set of stop words for different languages, including English.\n",
    "   - The `stopwords.words(\"english\")` function retrieves the set of English stop words.\n",
    "   - The set of stop words is stored in the `stop_words` variable.\n",
    "   - A list comprehension is used to create a new list called `filtered_tokens`.\n",
    "   - Each token in the `tokens` list is checked against the set of stop words.\n",
    "   - If a token, when converted to lowercase, is not present in the stop words set, it is included in the `filtered_tokens` list.\n",
    "   - The resulting `filtered_tokens` list will contain only the tokens from the original sentence that are not considered stop words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ef170275",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T10:28:25.881775Z",
     "start_time": "2023-07-07T10:28:25.878333Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: This is a sample sentence.\n",
      "Tokens: ['This', 'is', 'a', 'sample', 'sentence', '.']\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Text:\", text)\n",
    "print(\"Tokens:\", tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d873e60c",
   "metadata": {},
   "source": [
    "Tokens: The text is tokenized into individual words or punctuation marks. The tokens for the given text are ['This', 'is', 'a', 'sample', 'sentence', '.']."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04ba66e",
   "metadata": {},
   "source": [
    "#### Lemmatization or Stemming (Optional)\n",
    "\n",
    "Apply lemmatization or stemming to reduce words to their base or root form. Both lemmatization and stemming help in reducing variations of words to their base forms, which can be useful for tasks such as information retrieval, text analysis, or language modeling. Choosing between lemmatization and stemming depends on the specific requirements of your application or task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9c4590e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T10:28:25.887860Z",
     "start_time": "2023-07-07T10:28:25.883853Z"
    }
   },
   "outputs": [],
   "source": [
    "# Lemmatization\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
    "\n",
    "# Stemming\n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "stemmed_tokens = [stemmer.stem(token) for token in filtered_tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0cd87d",
   "metadata": {},
   "source": [
    "1. Lemmatization:\n",
    "   - The line `lemmatizer = nltk.stem.WordNetLemmatizer()` creates an instance of the WordNetLemmatizer class from the NLTK library.\n",
    "   - Lemmatization is the process of reducing words to their base or root form (lemmas) to improve analysis or comparison.\n",
    "   - The list comprehension `[lemmatizer.lemmatize(token) for token in filtered_tokens]` applies lemmatization to each token in the `filtered_tokens` list.\n",
    "   - The lemmatized tokens are stored in the `lemmatized_tokens` list.\n",
    "\n",
    "2. Stemming:\n",
    "   - The line `stemmer = nltk.stem.PorterStemmer()` creates an instance of the PorterStemmer class from the NLTK library.\n",
    "   - Stemming is the process of reducing words to their base or root form by removing suffixes.\n",
    "   - The list comprehension `[stemmer.stem(token) for token in filtered_tokens]` applies stemming to each token in the `filtered_tokens` list.\n",
    "   - The stemmed tokens are stored in the `stemmed_tokens` list.\n",
    "\n",
    "The goal of this code is to showcase two different text normalization techniques: lemmatization and stemming.\n",
    "\n",
    "- Lemmatization aims to obtain the base or root form of words. For example, the lemma of \"running\" is \"run\" and the lemma of \"better\" is \"good\".\n",
    "- Stemming, on the other hand, reduces words to their base form by removing common suffixes. For example, stemming \"running\" would result in \"run\" and stemming \"better\" would become \"bet\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "481cba05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T10:28:25.893180Z",
     "start_time": "2023-07-07T10:28:25.889987Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Tokens: ['sample', 'sentence', '.']\n",
      "Lemmatized Tokens: ['sample', 'sentence', '.']\n",
      "Stemmed Tokens: ['sampl', 'sentenc', '.']\n"
     ]
    }
   ],
   "source": [
    "print(\"Filtered Tokens:\", filtered_tokens)\n",
    "print(\"Lemmatized Tokens:\", lemmatized_tokens)\n",
    "print(\"Stemmed Tokens:\", stemmed_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61140509",
   "metadata": {},
   "source": [
    "- Lemmatized Tokens: The filtered tokens are lemmatized, meaning they are reduced to their base or dictionary form. In this case, since the tokens don't have inflectional endings, the lemmatized tokens remain the same as the filtered tokens: ['sample', 'sentence', '.'].\n",
    "\n",
    "- Stemmed Tokens: The filtered tokens are stemmed, meaning they are reduced to their root form by removing suffixes. In this case, the stemmed tokens are ['sampl', 'sentenc', '.']."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b7dd8c",
   "metadata": {},
   "source": [
    "#### Named Entity Recognition (NER) using spaCy (Optional)\n",
    "\n",
    "Perform named entity recognition to extract entities from the text. This information can be useful in various applications, such as information extraction, question-answering systems, or data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "013dc871",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T10:28:26.544353Z",
     "start_time": "2023-07-07T10:28:25.895267Z"
    }
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(text)\n",
    "entities = [(entity.text, entity.label_) for entity in doc.ents]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7272547a",
   "metadata": {},
   "source": [
    "1. Loading the Language Model:\n",
    "   - The line `nlp = spacy.load(\"en_core_web_sm\")` loads the English language model from spaCy. This model includes pre-trained word vectors, syntax, entities, and other linguistic annotations.\n",
    "\n",
    "2. Processing the Text:\n",
    "   - The line `doc = nlp(text)` processes the input text using the loaded language model. The `text` variable contains the text you want to analyze.\n",
    "   - The `nlp` object processes the text and creates a `doc` object that contains the analyzed information, such as tokens, part-of-speech tags, syntactic dependencies, and named entities.\n",
    "\n",
    "3. Extracting Named Entities:\n",
    "   - Named entity recognition (NER) is a natural language processing task that aims to locate and classify named entities in text.\n",
    "   - The line `entities = [(entity.text, entity.label_) for entity in doc.ents]` extracts the named entities from the `doc` object.\n",
    "   - The list comprehension retrieves the text and label of each named entity in the `doc.ents` attribute.\n",
    "   - The `entities` variable stores the extracted named entities as tuples, where each tuple contains the entity text and its corresponding label.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e5fe7406",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T10:28:26.550260Z",
     "start_time": "2023-07-07T10:28:26.546792Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Named Entities: []\n"
     ]
    }
   ],
   "source": [
    "print(\"Named Entities:\", entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3651744e",
   "metadata": {},
   "source": [
    "Named Entities: No named entities were detected in the original text, so the list of named entities is empty: []."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d960abb",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In conclusion, this section provided an introduction to Generative AI, Large Language Models (LLM), and their real-world applications. We explored how LLMs can be used in various business contexts, highlighting their versatility and potential impact. Additionally, we covered the basics of Python programming for language preprocessing, including variables, data types, operations, and control structures. We delved into the field of Natural Language Processing (NLP) and discussed word embeddings, major text libraries in Python (such as NLTK and spaCy), and the importance of text preprocessing and tokenization. Through demonstrations and examples, we gained practical insights into utilizing these libraries for simple text processing tasks. By building a solid foundation in these areas, participants will be well-equipped to delve further into the fascinating world of Generative AI and LLMs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_dev",
   "language": "python",
   "name": "llm_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
